<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Adam Faris</title>
    <link>https://amf3.github.io/</link>
    <description>Recent content on Adam Faris</description>
    <generator>Hugo -- 0.147.9</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 21:11:43 -0700</lastBuildDate>
    <atom:link href="https://amf3.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Go Generics: A Real World Use Case</title>
      <link>https://amf3.github.io/articles/code/go/real_world_generics/</link>
      <pubDate>Fri, 11 Jul 2025 21:11:43 -0700</pubDate>
      <guid>https://amf3.github.io/articles/code/go/real_world_generics/</guid>
      <description>Using Generics for Testing Pointers In Structs</description>
      <content:encoded><![CDATA[<p>Until recently, I haven&rsquo;t had many opportunities to use Go&rsquo;s generics.  I ran into
a case where generics make sense.  Best of all, this isn&rsquo;t a contrived example.</p>
<p>I&rsquo;m working on a project and using openAPI to generate API contracts.  One of the generated
structs contains optional fields implemented as pointers. The only required field is Name.</p>
<pre tabindex="0"><code>const (
	Gzip PostPailsCompression = &#34;gzip&#34;
	None PostPailsCompression = &#34;none&#34;
)

type PostPails struct {
	Compression *PostPailsCompression `json:&#34;compression,omitempty&#34;`

	// MaxArchiveSize Max size (bytes) before rotating to a new archive.
	MaxArchiveSize *int `json:&#34;max_archive_size,omitempty&#34;`

	// Name Name of the new pail
	Name string `json:&#34;name&#34;`
}
</code></pre><p>I need to populate the struct with values when writing unit tests. But dealing with pointers in Go
test code usually results in using temporary variables.  It&rsquo;s not bad, but there&rsquo;s some visual noise.</p>
<pre tabindex="0"><code>gzip := PostPailsCompression(&#34;gzip&#34;)
size := 1000000
payload := PostPails{
    Name: &#34;testpail&#34;
    Compression: &amp;gzip,
    MaxArchiveSize: &amp;size,
}
</code></pre><p>Implementing a helper function using generics, provides a much cleaner solution.</p>
<ul>
<li>The temporary variables are no longer needed.</li>
<li>Test code becomes much easier to read by naming the helper function ptr.</li>
</ul>
<pre tabindex="0"><code>func ptr[T any](v T) *T {
	return &amp;v
}

func TestPostPails_CreatesDirectory(t *testing.T) {
	tmpStorage := t.TempDir()
	server := NewServer(tmpStorage)

	payload := PostPails{
		Name:           &#34;testpail&#34;,
		Compression:    ptr(PostPailsCompression(&#34;gzip&#34;)),
		MaxArchiveSize: ptr(1000000),
        ... 
}
</code></pre><p>Let&rsquo;s discuss the ptr function.</p>
<ul>
<li>T is a type parameter and is a placeholder for any type.</li>
<li>The any constraint means T can be anything and is equivalent to interface{}.</li>
<li>Inside the function, we take a value v and return its pointer.</li>
</ul>
<hr>
<p>Using generics avoids the temporary variable pattern and provides a means to write cleaner test code.
The benefit becomes obvious when dealing with many optional fields.</p>
<p>Until now, generics didn&rsquo;t seem to be a feature I needed.  The examples I read about didn&rsquo;t feel relevant.  This one clicked because
it solved a real issue while writing unit tests.</p>
<p>Any thoughts or clever uses of Go generics? Drop me a line on <a href="https://bsky.app/profile/af9.us">Bluesky</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>OpenAPI in Practice: Go Server &#43; Python Client from Spec</title>
      <link>https://amf3.github.io/articles/api/hello_openapi/</link>
      <pubDate>Fri, 04 Jul 2025 22:43:09 -0700</pubDate>
      <guid>https://amf3.github.io/articles/api/hello_openapi/</guid>
      <description>A practical walkthrough of using OpenAPI to generate cross-language interfaces</description>
      <content:encoded><![CDATA[<p>OpenAPI is a specification for documenting HTTP APIs for both humans and machines to consume.  As OpenAPI is a specification,
it is language agnostic. OpenAPI relies on generators for translating the specification.  There&rsquo;s more
than just documentation that&rsquo;s generated. Generators also create language-specific interfaces, tooling, and contracts.  In some
ways the OpenAPI pattern reminds me of either protobuf with gRPC or ORM schema-first design.  As a result, a declarative API is
created by the tooling.</p>
<p>By the end of this post you&rsquo;ll have:</p>
<ul>
<li>A working Go http server generated from an OpenAPI specification.</li>
<li>A Python http client generated from the same specification and authenticates with basic auth.</li>
<li>Insight into common OpenAPI pitfalls and how to avoid them.</li>
</ul>
<pre tabindex="0"><code class="language-ascii" data-lang="ascii">[openapi.yaml]
     ↓
+--------------+
| oapi-codegen | ---&gt; [Go Server]
+--------------+
     ↓
+-----------------------+
| openapi-python-client | ---&gt; [Python Client]
+-----------------------+
</code></pre><p>If you would like to follow along, a complete code example can be <a href="./assets/hello_openapi.tar.gz"><strong>downloaded</strong></a> and extracted
into a temporary working directory.</p>
<h2 id="generators">Generators</h2>
<p>Because generators are consuming the specification, the OpenAPI version is determined by what the generators support.</p>
<p>For example, a popular Go generator is <a href="https://github.com/oapi-codegen/oapi-codegen">oapi-codegen</a> and supports
OpenAPI 3.0.  Where a popular Python generator named
<a href="https://github.com/openapi-generators/openapi-python-client">openapi-python-client</a> can support both OpenAPI 3.0 and 3.1 specifications.</p>
<p>Generators can be downloaded and managed as part of the languages tooling.  For Go, the oapi-codegen generator is managed with Go
modules and invoked with <code>go tool oapi-codegen</code>.  With Python, creating a virtual environment, using
pip install openapi-python-client, and pip freeze &gt; requirements.txt will work nicely.</p>
<h2 id="openapi-schema">OpenAPI Schema</h2>
<p>At first it wasn&rsquo;t clear to me on how to get started with OpenAPI or what the benefits were.  This is even after reviewing the
OpenAPI <a href="https://spec.openapis.org/oas/v3.0.3.html">schema documentation</a> for 3.0.3.</p>
<p>To get started one needs to create a specification.  A very minimal specification meeting the 3.0.x requirements is listed below.
It&rsquo;s not a very interesting example as endpoints in the application server aren&rsquo;t defined, but it shows how minimal a
specification can be that meets schema requirements.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">openapi</span>: <span style="color:#e6db74">&#34;3.0.3&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">info</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">1.0.0</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">title</span>: <span style="color:#ae81ff">My Contrived Server</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">paths</span>:
</span></span></code></pre></div><p>Let&rsquo;s get started by extending the simple example defining a path named /status. It will return a 200 response code with a JSON resonse.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">/status</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">get</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">responses</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#39;200&#39;</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Get status of the application server</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">content</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">application/json</span>:
</span></span><span style="display:flex;"><span>              <span style="color:#f92672">schema</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">$ref</span>: <span style="color:#e6db74">&#39;#/components/schemas/status&#39;</span>
</span></span></code></pre></div><p>The JSON response is documented in a separate YAML block named components. It defines the response containing a JSON
map containing the keys &ldquo;state&rdquo; and &ldquo;message&rdquo;, both of which have a string value.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">components</span>: 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">schemas</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">type</span>: <span style="color:#ae81ff">object</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">properties</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">state</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">type</span>: <span style="color:#ae81ff">string</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">example</span>: <span style="color:#e6db74">&#34;GOOD&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">message</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">type</span>: <span style="color:#ae81ff">string</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">example</span>: <span style="color:#e6db74">&#34;App running within parameters&#34;</span>
</span></span></code></pre></div><p>OpenAPI supports tags, which let you group related endpoints. This example creates a data grouping and puts create_bucket in the group.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">tags</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">data</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">description</span>:  <span style="color:#ae81ff">data manipulation endpoints</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">/create_bucket</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">post</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">tags</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">data</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">requestBody</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">required</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">content</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">application/json</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">schema</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">$ref</span>: <span style="color:#e6db74">&#39;#/components/schemas/create_bucket&#39;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">responses</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#39;200&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Create a storage object</span>
</span></span></code></pre></div><p>The OpenAPI specification also provides a definition for authentication to the web application.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">components</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">securitySchemes</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">basicAuth</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">type</span>: <span style="color:#ae81ff">http</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">scheme</span>: <span style="color:#ae81ff">basic</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Endpoints protected by basic auth base64 encoded credentials.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">paths</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">/status</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">get</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">security</span>:
</span></span><span style="display:flex;"><span>                - <span style="color:#f92672">basicAuth</span>: []
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">responses</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#39;200&#39;</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">description</span>: <span style="color:#ae81ff">Get status of the application server</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">content</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">application/json</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">schema</span>:
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">$ref</span>: <span style="color:#e6db74">&#39;#/components/schemas/status&#39;</span>
</span></span></code></pre></div><p>Earlier I mentioned the generators will create interface files. Declarations which are considered middleware like
authentication or logging are out of scope for OpenAPI.
In this example, the security entries are there to document that the endpoints require basic authentication.</p>
<h2 id="generate-server-interfaces-go">Generate Server Interfaces (Go)</h2>
<p>The server walkthrough presumes one has both Make and Go installed, and the <a href="./assets/hello_openapi.tar.gz">example code</a> (tar.gz file)
has been downloaded and extracted into a temp/work directory.</p>
<ul>
<li>Download the Go dependencies, including oapi-codegen, by running <code>make tidy</code>.</li>
<li>Generate the server interfaces by running <code>make server-codegen</code>, which calls <code>go tool oapi-codegen</code>.</li>
</ul>
<p>Feel free to inspect the api/http.gen.go file before proceeding. You&rsquo;ll see it contains an interface named ServerInterface,
which has the GetStatus or PostStatus endpoints from the OpenAPI specification.  http.gen.go also contains a struct named Status
that was defined from components -&gt; schema -&gt; status.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Status</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Message</span> <span style="color:#66d9ef">string</span> <span style="color:#e6db74">`json:&#34;message&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">State</span>   <span style="color:#66d9ef">string</span> <span style="color:#e6db74">`json:&#34;state&#34;`</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>To see the working application server, run <code>make server-run</code>.</p>
<p>The server has Basic Auth enabled with hardcoded credentials. The user is &ldquo;alice&rdquo; and the password &ldquo;mySecretPW&rdquo;.  Curl can be
used to see the response.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% curl --basic -u alice:mySecretPW  http://localhost:8080/status
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span><span style="color:#e6db74">&#34;message&#34;</span>:<span style="color:#e6db74">&#34;Initializing&#34;</span>,<span style="color:#e6db74">&#34;state&#34;</span>:<span style="color:#e6db74">&#34;Unknown&#34;</span><span style="color:#f92672">}</span>
</span></span></code></pre></div><h2 id="generate-client-interfaces-python">Generate Client Interfaces (Python)</h2>
<p>This is where OpenAPI really shines.  I was able to use a generator to create Python libraries
to be used by the client implementation code.  The walkthrough presumes a recent version of Python3 and pip are installed.</p>
<p>First, create a virtual environment and install the openapi-python-client dependencies.  This shell snippet
presumes the current working directory is already hello_openapi.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% python3 -mvenv $PWD/.venv
</span></span><span style="display:flex;"><span>% source $PWD/.venv/bin/activate
</span></span><span style="display:flex;"><span>% pip install -r requirements.txt
</span></span></code></pre></div><p>Then run <code>make client-codegen</code> to build the Python client libraries located in cmd/client/my_contrived_server.</p>
<p>Generating the client was easy, but figuring out how to pass authentication took some trial and error. I eventually
realized that the <code>token</code> is just a base64-encoded <code>username:password</code> string, and the <code>prefix</code> should be set to <code>Basic</code>.</p>
<pre tabindex="0"><code>client = AuthenticatedClient(
    base_url=&#34;http://127.0.0.1:8080&#34;,
    headers={&#34;Content-Type&#34;: &#34;application/json&#34;, &#34;Accept&#34;: &#34;application/json&#34;},
    token=&#34;YWxpY2U6bXlTZWNyZXRQVw==&#34;,  # Token string is a base64 string containing alice:mySecretPW
    prefix=&#34;Basic&#34;
)
</code></pre><p>To see the client in action, run <code>make client-run</code>.  Also take a look at cmd/client/client.py.  It
only took a few lines of python code to implement what the openapi-python-client generator had created.</p>
<h2 id="gotchas--lessons-learned">Gotchas &amp; Lessons Learned</h2>
<p>One issue I have with OpenAPI is the illusion of simplicty. When I first started working with OpenAPI, I noticed the Status struct
had keys referencing a pointer of strings which wasn&rsquo;t ideal.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">type</span> <span style="color:#a6e22e">Status</span> <span style="color:#66d9ef">struct</span> {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">Message</span> <span style="color:#f92672">*</span><span style="color:#66d9ef">string</span> <span style="color:#e6db74">`json:&#34;message&#34;`</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">State</span>   <span style="color:#f92672">*</span><span style="color:#66d9ef">string</span> <span style="color:#e6db74">`json:&#34;state&#34;`</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>It took some fiddling with the OpenAPI specification to make the generator use strings instead of pointers to strings.
Adding &lsquo;required&rsquo; to the schema made the generator do what I wanted.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">components</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">status</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">type</span>: <span style="color:#ae81ff">object</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">properties</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">state</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">type</span>: <span style="color:#ae81ff">string</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">example</span>: <span style="color:#e6db74">&#34;GOOD&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">message</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">type</span>: <span style="color:#ae81ff">string</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">example</span>: <span style="color:#e6db74">&#34;App within parameters&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">required</span>:
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">state</span>
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">message</span>
</span></span></code></pre></div><p>Another issue was not knowing that in Paths, GETs should have a <strong>responses</strong> entry and POSTS should have a <strong>RequestBody</strong> entry.
It makes sense, but it wasn&rsquo;t obvious to me when stumbling through hello-world.</p>
<p>The main takeaway? Always inspect the generated code. If something doesn’t look right, like unexpected pointers or missing method args,
chances are your spec needs tweaking.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Even though I hit some issues with a fairly simple example, I&rsquo;m going to continue using OpenAPI specifcations.  Being able to easily generate
client code in a different language was a real win. And let&rsquo;s not forget the free API documentation and contract definitions which comes with OpenAPI.
I have a more complex OpenAPI project coming up. I&rsquo;m sure I&rsquo;ll have more notes (and probably more gotchas) to share.  Stay tuned.</p>
<p>If you&rsquo;ve had similar struggles with OpenAPI or tips for improving schema design, I’d love to hear them on <a href="https://bsky.app/profile/af9.us">Bluesky Social</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>DIY Docker Volume Drivers: What&#39;s Missing</title>
      <link>https://amf3.github.io/articles/storage/docker_volumes/</link>
      <pubDate>Thu, 26 Jun 2025 22:37:40 -0700</pubDate>
      <guid>https://amf3.github.io/articles/storage/docker_volumes/</guid>
      <description>How to write a simple volume plugin. No root, no FUSE, just HTTP and Go</description>
      <content:encoded><![CDATA[<p>With Docker, it’s not always obvious what storage options exist beyond the built-in <strong>local</strong> volume driver or a traditional <strong>bind mount</strong>.
Exploring Docker volume drivers often turns up archived GitHub repositories or commercially backed plugins tied to specific cloud storage products. The volume
ecosystem is especially limited for on-premise storage, and many plugins require more privileges than you&rsquo;d expect.</p>
<p>In this post, I’ll cover how Docker handles volume storage under the hood. I’ll also walkthrough how to create a volume plugin that interacts with remote
storage without needing CAP_SYS_ADMIN privileges.</p>
<h2 id="docker-storage-overview">Docker Storage Overview</h2>
<ul>
<li><strong>Graph Drivers</strong> (also known as Storage Drivers) manage image and container layers. Examples include, <strong>overlay2</strong>, <strong>zfs</strong>, or <strong>btrfs</strong>.</li>
<li><strong>Volume Drivers</strong> manange named volumes and allow data to persist outside of the container lifecycle.</li>
</ul>
<p>Plugins for Volume Drivers are usually installed as special containers using the <strong>docker plugin</strong> command. Plugin containers run
in their own namespaces and don&rsquo;t behave like normal containers. However, if the plugin includes a shell, it&rsquo;s possible to enter the
namespace using <a href="https://docs.docker.com/engine/extend/#debugging-plugins">runc</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>ubuntu@docker-dev:~/work$ sudo runc --root /run/docker/runtime-runc/plugins.moby list 
</span></span><span style="display:flex;"><span>ID                                                                 PID         STATUS      BUNDLE                                                                                                                        CREATED                          OWNER
</span></span><span style="display:flex;"><span>bae595da4deac656921a48f4b3d854992c692777f46db891934310ae863746c1   <span style="color:#ae81ff">24503</span>       running     /run/containerd/io.containerd.runtime.v2.task/plugins.moby/bae595da4deac656921a48f4b3d854992c692777f46db891934310ae863746c1   2025-06-27T03:55:42.927740463Z   root
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ubuntu@docker-dev:~/work$ sudo runc --root /run/docker/runtime-runc/plugins.moby exec -t bae595da4deac656921a48f4b3d854992c692777f46db891934310ae863746c1 /bin/bash
</span></span><span style="display:flex;"><span>root@docker-dev:/# ls -lh /myplugin
</span></span><span style="display:flex;"><span>-rwxr-xr-x <span style="color:#ae81ff">1</span> root root 5.0M Jun <span style="color:#ae81ff">24</span> 23:24 /myplugin
</span></span></code></pre></div><p>The Docker daemon communicates with all plugins over HTTP, using either a Unix socket or a TCP socket.</p>
<h2 id="whats-missing">What&rsquo;s Missing</h2>
<p>While the interface is simple, expectations around what happens after a volume is mounted are not. Most plugins end up mounting a remote
filesystem like NFS or CIFS, manipulating files as root, or interacting with device nodes like /dev/fuse, all requiring elevated privileges.</p>
<p>To summarize:</p>
<ul>
<li>It’s difficult to find unprivileged plugins in the Docker ecosystem.</li>
<li>Using virtual filesystems (like GlusterFS, SSHFS, or S3FS) requires FUSE, and FUSE needs CAP_SYS_ADMIN.</li>
<li>A local caching layer for remote storage is not baked into the Docker volume plugin interface.</li>
</ul>
<h2 id="the-diy-approach">The DIY Approach</h2>
<p>Let’s say we want a volume plugin that “mounts” a remote volume by downloading files from a remote server.</p>
<p>Here’s a basic outline of how it might work:</p>
<ul>
<li>Implement a volume plugin that exposes the Volume Plugin API to the Docker daemon.</li>
<li><strong>Create</strong> volume, populates volume metadata needed to later identify the volume within Docker. (The API allows actual filesystem setup to be deferred until Mount.)</li>
<li><strong>Mount</strong> volume, will fetch data from the remote server, extract it to a known local path, and return that path to Docker.</li>
<li><strong>Unmount</strong> volume, either cleans up the local path or repackages and uploads any changes back to the remote server.</li>
</ul>
<p>This model avoids the need for root privileges, since it doesn&rsquo;t touch /dev, doesn&rsquo;t rely on FUSE, and doesn’t call mount(2).</p>
<h2 id="my-interest-in-docker-plugins">My Interest in Docker Plugins</h2>
<p>I like the simplicity of Docker compared to larger orchestration platforms, but I want more from its storage offerings.
When I started looking at existing volume plugins, a few things pushed me toward writing my own.</p>
<p>Many plugins require root-level privileges. I found that avoiding FUSE or skipping filesystems that depend on kernel modules could reduce or eliminate
this requirement.</p>
<p>Another issue, most volume plugins on GitHub have been archived by their maintainers. I get it, people move on and the Docker community isn&rsquo;t as large
as it once was.  That said, I found the developer tooling for writing plugins to be a bit clunky. My hope is this post will help fill in gaps and show
a practical path forward for building a volume plugin.</p>
<p>Finally, most active (not archived) volume plugins I find are designed for cloud storage services. There&rsquo;s a lack of unprivileged lightweight volume
plugins and I think there&rsquo;s a place for something simplier.</p>
<ul>
<li>Streaming read-only config bundles</li>
<li>CI/CD ephemeral volumes</li>
<li>Lazy-loading assets over HTTP</li>
</ul>
<p>These ideas are viable with the current plugin API, just unexplored.</p>
<h2 id="a-simple-plugin">A simple plugin</h2>
<p>After digging into Docker plugins and exploring the current state of the ecosystem, I decided to build a simple plugin to see how far I could get
with minimal privileges and lightweight tooling. I have to admit that the process was both educational and a little frustrating.</p>
<h3 id="what-didnt-go-smoothly">What Didn&rsquo;t Go Smoothly</h3>
<p>Docker has a clean CLI and a solid container runtime, but plugin development comes with its share of friction:</p>
<ul>
<li>The development loop is slow. Building, loading, and enabling a plugin requires several manual steps. Debugging inside the plugin container via runc (instead of docker plugin) isn’t intuitive.</li>
<li>Plugin files need to follow a specific directory structure, and you must include an exported container root filesystem in a subdirectory before the plugin can be built.</li>
<li>The Docker daemon uses a socket path that includes the container ID which is a dynamic value. This caused the daemon to time out when connecting to the plugin until I manually fixed the path. Eventually, I discovered the Go plugin SDK, which handled this more reliably.</li>
</ul>
<h3 id="build-steps">Build Steps</h3>
<p>Here’s a high-level overview of the development loop when creating a Docker volume plugin:</p>
<ol>
<li>Write the plugin code.</li>
<li>Create a Docker image that contains the plugin.</li>
<li>Create a throwaway container from that image.</li>
<li>Extract the root filesystem from the container using <strong>docker export</strong>, and untar it into a directory named <strong>rootfs</strong>.</li>
<li>Finally, run <strong>docker plugin create</strong> to assemble the plugin from the <strong>rootfs</strong> and a <em><strong>config.json</strong></em> file.</li>
</ol>
<p><img alt="Docker Documentation Screenshot of Building a Plugin" loading="lazy" src="/articles/storage/docker_volumes/assets/doc.jpg"></p>
<p>Fortunately, someone wrapped these steps in a <a href="https://github.com/vieux/docker-volume-sshfs/blob/1e0cd2fcb72d6af0a2ad4689faed8c312124517c/Makefile">Makefile</a>
which can be used as a starting point.  Here&rsquo;s a snippet from the docker-volume-sshfs repo.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-make" data-lang="make"><span style="display:flex;"><span><span style="color:#a6e22e">rootfs</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	@echo <span style="color:#e6db74">&#34;### docker build: rootfs image with docker-volume-sshfs&#34;</span>
</span></span><span style="display:flex;"><span>	@docker build -q -t <span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span>:rootfs .
</span></span><span style="display:flex;"><span>	@echo <span style="color:#e6db74">&#34;### create rootfs directory in ./plugin/rootfs&#34;</span>
</span></span><span style="display:flex;"><span>	@mkdir -p ./plugin/rootfs
</span></span><span style="display:flex;"><span>	@docker create --name tmp <span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span>:rootfs
</span></span><span style="display:flex;"><span>	@docker export tmp | tar -x -C ./plugin/rootfs
</span></span><span style="display:flex;"><span>	@echo <span style="color:#e6db74">&#34;### copy config.json to ./plugin/&#34;</span>
</span></span><span style="display:flex;"><span>	@cp config.json ./plugin/
</span></span><span style="display:flex;"><span>	@docker rm -vf tmp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">create</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	@echo <span style="color:#e6db74">&#34;### remove existing plugin </span><span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span><span style="color:#e6db74">:</span><span style="color:#e6db74">${</span>PLUGIN_TAG<span style="color:#e6db74">}</span><span style="color:#e6db74"> if exists&#34;</span>
</span></span><span style="display:flex;"><span>	@docker plugin rm -f <span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span>:<span style="color:#e6db74">${</span>PLUGIN_TAG<span style="color:#e6db74">}</span> <span style="color:#f92672">||</span> true
</span></span><span style="display:flex;"><span>	@echo <span style="color:#e6db74">&#34;### create new plugin </span><span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span><span style="color:#e6db74">:</span><span style="color:#e6db74">${</span>PLUGIN_TAG<span style="color:#e6db74">}</span><span style="color:#e6db74"> from ./plugin&#34;</span>
</span></span><span style="display:flex;"><span>	@docker plugin create <span style="color:#e6db74">${</span>PLUGIN_NAME<span style="color:#e6db74">}</span>:<span style="color:#e6db74">${</span>PLUGIN_TAG<span style="color:#e6db74">}</span> ./plugin
</span></span></code></pre></div><p>You’ll also need a <strong>config.json</strong> file (<a href="https://docs.docker.com/engine/extend/config/">docs</a>) that defines the plugin’s name, entrypoint, socket permissions,
and other settings. This file goes alongside the rootfs directory when building the plugin.</p>
<h3 id="plugin-sdk-and-api-documentation">Plugin SDK and API documentation</h3>
<p>The <a href="https://github.com/docker/go-plugins-helpers/tree/main/volume">go-plugins-helpers</a> SDK was a big help when building my plugin, though
it&rsquo;s not well advertised.  It provides an interface with method definitions for handling the HTTP communication between the custom plugin and
the Docker Daemon.</p>
<p>While plugins can technically be written in any language (since the API is just HTTP), this Go SDK was the only official helper library I found.  That said,
using it is optional.  I came across several projects like rclone and SeaweedFS that implement the plugin protocol without relying on the SDK.</p>
<p>Docker’s documentation is spread across a few key pages. The two most useful I found were:</p>
<ul>
<li>The <a href="https://docs.docker.com/engine/extend/plugin_api/">Plugin API reference</a> describes the HTTP interface and includes example request and response payloads.</li>
<li>The <a href="https://docs.docker.com/engine/extend/plugins_volume/">Volume plugin overview</a> includes sections on creating, installing, developing, and debugging plugins.</li>
</ul>
<h3 id="code-highlights">Code Highlights</h3>
<p>The plugin I built is intentionaly minimal.  When a container calls <strong>mount</strong> on the volume, the function creates a hello.txt file in the volume directory.<br>
It simulates downloading data from remote storage while keeping things simple:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-Go" data-lang="Go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">d</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">myDriver</span>) <span style="color:#a6e22e">Mount</span>(<span style="color:#a6e22e">req</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">volume</span>.<span style="color:#a6e22e">MountRequest</span>) (<span style="color:#f92672">*</span><span style="color:#a6e22e">volume</span>.<span style="color:#a6e22e">MountResponse</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">volPath</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">filepath</span>.<span style="color:#a6e22e">Join</span>(<span style="color:#a6e22e">pluginRoot</span>, <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">Name</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Write a hello.txt file</span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">helloFile</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">filepath</span>.<span style="color:#a6e22e">Join</span>(<span style="color:#a6e22e">volPath</span>, <span style="color:#e6db74">&#34;hello.txt&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">os</span>.<span style="color:#a6e22e">WriteFile</span>(<span style="color:#a6e22e">helloFile</span>, []byte(<span style="color:#e6db74">&#34;Hello, world!\n&#34;</span>), <span style="color:#ae81ff">0644</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;failed to write hello.txt: %w&#34;</span>, <span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#a6e22e">log</span>.<span style="color:#a6e22e">Printf</span>(<span style="color:#e6db74">&#34;Mount volume: %s -&gt; %s&#34;</span>, <span style="color:#a6e22e">req</span>.<span style="color:#a6e22e">Name</span>, <span style="color:#a6e22e">volPath</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> <span style="color:#f92672">&amp;</span><span style="color:#a6e22e">volume</span>.<span style="color:#a6e22e">MountResponse</span>{<span style="color:#a6e22e">Mountpoint</span>: <span style="color:#a6e22e">volPath</span>}, <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Before a container exits, <strong>unmount</strong> is called.  This function deletes the file from the volume, demonstrating that the basic lifecycle works with user level
permissions. This step could be used to sync local changes back to remote storage in production code.</p>
<pre tabindex="0"><code>func (d *myDriver) Unmount(req *volume.UnmountRequest) error {
	volPath := filepath.Join(pluginRoot, req.Name)
	helloFile := filepath.Join(volPath, &#34;hello.txt&#34;)

	// Simulate cleanup
	if err := os.Remove(helloFile); err != nil &amp;&amp; !os.IsNotExist(err) {
		return fmt.Errorf(&#34;unmount cleanup error: %w&#34;, err)
	}

	log.Printf(&#34;Unmount volume: %s (removed hello.txt)&#34;, req.Name)
	return nil
}
</code></pre><h3 id="build-walkthrough">Build WalkThrough</h3>
<p>Now for the good part.  A full walkthrough of how I built and tested the custom plugin. Here are the files involved:</p>
<ul>
<li><a href="./assets/go.mod">go.mod</a></li>
<li><a href="./assets/go.sum">go.sum</a></li>
<li><a href="./assets/myplugin.go">myplugin.go</a></li>
<li><a href="./assets/Dockerfile">Dockerfile</a></li>
<li><a href="./assets/config.json">config.json</a></li>
</ul>
<ol>
<li>Build the Go code and create a plugin image</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ docker build -t rootfsimage .
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>+<span style="color:#f92672">]</span> Building 6.1s <span style="color:#f92672">(</span>13/13<span style="color:#f92672">)</span> FINISHED                                                                                                   docker:default
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>internal<span style="color:#f92672">]</span> load build definition from Dockerfile                                                                                 0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; transferring dockerfile: 461B                                                                                                 0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>internal<span style="color:#f92672">]</span> load metadata <span style="color:#66d9ef">for</span> docker.io/library/ubuntu:oracular                                                                   0.9s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>internal<span style="color:#f92672">]</span> load .dockerignore                                                                                                    0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; transferring context: 2B                                                                                                      0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>internal<span style="color:#f92672">]</span> load build context                                                                                                    0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; transferring context: 32.89kB                                                                                                 0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>builder 1/6<span style="color:#f92672">]</span> FROM docker.io/library/ubuntu:oracular@sha256:707879280c0bbfe6cbeb3ae1a85b564ea2356b5310a122c225b92cb3d1ed131b     0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; CACHED <span style="color:#f92672">[</span>builder 2/6<span style="color:#f92672">]</span> RUN apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get install golang-go ca-certificates -y                                          0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>builder 3/6<span style="color:#f92672">]</span> COPY . /build                                                                                                      0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>builder 4/6<span style="color:#f92672">]</span> WORKDIR /build                                                                                                     0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>builder 5/6<span style="color:#f92672">]</span> RUN go mod tidy                                                                                                    0.7s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>builder 6/6<span style="color:#f92672">]</span> RUN CGO_ENABLED<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span> go build -ldflags<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;-s -w -extldflags &#34;</span>-static<span style="color:#e6db74">&#34;&#34;</span> -tags netgo,osusergo -o myplugin                 4.3s 
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; CACHED <span style="color:#f92672">[</span>stage-1 2/3<span style="color:#f92672">]</span> RUN mkdir -p /run/docker/plugins /var/lib/myplugin/volumes                                                  0.0s 
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">[</span>stage-1 3/3<span style="color:#f92672">]</span> COPY --from<span style="color:#f92672">=</span>builder /build/myplugin /myplugin                                                                      0.0s 
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; exporting to image                                                                                                               0.0s 
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; exporting layers                                                                                                              0.0s 
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; writing image sha256:a3d2dee4d6cb8112f538a16056dc42b9761bda43f7f279b2a1f202a7a8e5f8ae                                         0.0s
</span></span><span style="display:flex;"><span> <span style="color:#f92672">=</span>&gt; <span style="color:#f92672">=</span>&gt; naming to docker.io/library/rootfsimage      
</span></span></code></pre></div><ol start="2">
<li>Create a container from the rootfs image and export the container’s root filesystem to a tar file.</li>
</ol>
<pre tabindex="0"><code>$ id=$(docker create rootfsimage true)  

$ echo $id
13cf6219737999bd54f7fc2537bc1218f42d9c45d92f79c4726c1422e81b348e

$ sudo docker export &#34;$id&#34; -o rootfs.tar 

$ ls -l rootfs.tar 
-rw------- 1 ubuntu ubuntu 110620160 Jun 26 23:07 rootfs.tar
</code></pre><ol start="3">
<li>Docker plugin tooling expects a rootfs directory and a config.json file in the current directory. The config isn’t part of the exported filesystem, so it&rsquo;s
provided separately:</li>
</ol>
<pre tabindex="0"><code>$ cp ~/Downloads/config.json .
$ sudo tar -xf ./rootfs.tar -C ./rootfs/ 

$ ls -l 
total 8
-rw-r--r--  1 root root  183 Jun 23 15:26 config.json
drwxr-xr-x 17 root root 4096 Jun 24 16:28 rootfs

$ ls rootfs
bin  boot  dev  etc  home  lib  media  mnt  myplugin  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
</code></pre><ol start="4">
<li>Create and enable the plugin.</li>
</ol>
<pre tabindex="0"><code>$ sudo docker plugin create myplugin . 
myplugin

$ docker plugin enable myplugin:latest
myplugin:latest

$ docker plugin ls
ID             NAME              DESCRIPTION                         ENABLED
d5f63b80f0b0   myplugin:latest   Example HTTP-backed volume plugin   true
</code></pre><ol start="5">
<li>Create a volume with the plugin and inspect it.</li>
</ol>
<pre tabindex="0"><code>$ docker volume create -d myplugin:latest abc123
abc123

$ docker volume ls
DRIVER            VOLUME NAME
myplugin:latest   abc123

$ docker volume inspect abc123 
[
    {
        &#34;CreatedAt&#34;: &#34;0001-01-01T00:00:00Z&#34;,
        &#34;Driver&#34;: &#34;myplugin:latest&#34;,
        &#34;Labels&#34;: null,
        &#34;Mountpoint&#34;: &#34;/var/lib/myplugin/volumes/abc123&#34;,
        &#34;Name&#34;: &#34;abc123&#34;,
        &#34;Options&#34;: null,
        &#34;Scope&#34;: &#34;local&#34;
    }
]
</code></pre><ol start="6">
<li>Mount the volume with a container.</li>
</ol>
<pre tabindex="0"><code>$ docker run -it --rm  -v abc123:/mnt alpine

/ # ls -l /mnt
total 4
-rw-r--r--    1 root     root            14 Jun 27 06:17 hello.txt

/ # cat /mnt/hello.txt 
Hello, world!
</code></pre><ol start="7">
<li>Additional information for Docker events can be found inside systemd logs.</li>
</ol>
<pre tabindex="0"><code>$ journalctl -u docker.service  | tail -3
Jun 26 23:17:55 docker-dev dockerd[7976]: time=&#34;2025-06-26T23:17:55-07:00&#34; level=error msg=&#34;2025/06/27 06:17:55 Mount volume: abc123 -&gt; /var/lib/myplugin/volumes/abc123&#34; plugin=d5f63b80f0b091582e00bfed7bd6d33e885fef876e151558a37ae5eaf05e5443
Jun 26 23:18:04 docker-dev dockerd[7976]: time=&#34;2025-06-26T23:18:04.543532903-07:00&#34; level=info msg=&#34;ignoring event&#34; container=0e6fdf10db3da9c9b5bc04bbe6abac6b23225578e796e89fe859c1d17fc57f0f module=libcontainerd namespace=moby topic=/tasks/delete type=&#34;*events.TaskDelete&#34;
Jun 26 23:18:04 docker-dev dockerd[7976]: time=&#34;2025-06-26T23:18:04-07:00&#34; level=error msg=&#34;2025/06/27 06:18:04 Unmount volume: abc123 (removed hello.txt)&#34; plugin=d5f63b80f0b091582e00bfed7bd6d33e885fef876e151558a37ae5eaf05e5443
</code></pre><h2 id="closing">Closing</h2>
<p>I&rsquo;m excited about learning how to create plugins for Docker and turning my notes into this post.</p>
<p>I made a previous post on using tar archives as an <a href="https://amf3.github.io/articles/storage/tar_objectstore/">object store</a> and I recently posted about compression ratios on Bluesky social.  Stay tuned to find out where these posts are headed.</p>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:plt47775q3cx3yw6r2efid2g/app.bsky.feed.post/3lruiz7tels2c" data-bluesky-cid="bafyreifcp7itwnmjzkp3br5rrt6fyyuwgqmegjalumg2cjxbbi2opl327q"><p lang="en">I was curious how snappy compared to lz4 and wrote a go program to find out.  Snappy seems to be a bit better with both compressed data output and resource usage.  

Input is the first 1,000,000 numbers of pi.</p>&mdash; <a href="https://bsky.app/profile/did:plc:plt47775q3cx3yw6r2efid2g?ref_src=embed">Adam Faris (@af9.us)</a> <a href="https://bsky.app/profile/did:plc:plt47775q3cx3yw6r2efid2g/post/3lruiz7tels2c?ref_src=embed">2025-06-18T07:40:31.631Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<p>If you&rsquo;ver ever built a Docker plugin or struggled with Docker storage, I&rsquo;d like to hear about it.  Any questions or ideas, reach out and
leave a comment.</p>
<p>Until next time, keep your volumes clean and your containers stateless.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Using Tar Files as Object Store Storage</title>
      <link>https://amf3.github.io/articles/storage/tar_objectstore/</link>
      <pubDate>Fri, 30 May 2025 16:46:07 -0700</pubDate>
      <guid>https://amf3.github.io/articles/storage/tar_objectstore/</guid>
      <description>Implementing Object Store storage with Log Structured Archives.</description>
      <content:encoded><![CDATA[<p>I&rsquo;m looking at how object storage systems manage data on disk. Especially the idea of using append only archives with an index for fast retrieveal.  While reading
Facebook&rsquo;s Haystack design, I noticed similarities to the tar file format and the potential to implement something similar at the local scale.</p>
<h2 id="haystack-overview">Haystack Overview</h2>
<p>There are several components mentioned in the original <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf">Haystack paper</a>, but at
the core is the Haystack Store, where end user image files are physically kept. Instead of writing files directly to the filesystem, images are appended
to a large file called a <strong>volume</strong>, which acts as an append-only archive. Each volume is typically capped at around 100 GB and is aligned to 8-byte
offsets.  Image files within this volume are referred to as <strong>needles</strong>.</p>
<p><img alt="Haystack Volume Description" loading="lazy" src="/articles/storage/tar_objectstore/assets/needles.png#center"></p>
<p>A volume begins with a superblock (the paper doesn’t describe this in detail), followed by the header for the first needle (file). Each needle within
the volume has its own header, containing metadata like file size, checksums, and flags. The flags field includes a bit to indicate deletion status.</p>
<p>Since the volume is append-only, deletions don’t reclaim space—they&rsquo;re simply marked as deleted in the needle’s header. A background process can later
compact the volume if needed. To keep track of where each needle is within the file, an in-memory index maps file IDs to byte offsets.</p>
<p>When a read request comes in, the Haystack Store performs a direct seek to the needle’s offset, verifies the flags to check if it&rsquo;s deleted, and returns
the data if is not tombstoned.  Deletions update both the in-memory index and the needle’s header to mark the entry as removed.</p>
<p>This model provides two big wins:</p>
<ul>
<li><strong>Storage efficiency:</strong> Small files, like 1 KB thumbnails, don’t waste space the way they would on a traditional filesystem with 4 KB blocks. Instead of allocating a full block per file, they&rsquo;re packed into a shared archive.</li>
<li><strong>Fast retrieval:</strong> There’s no need to scan directory structures or fetch inode metadata. With an open file handle to the volume and an in-memory index, reads are just a seek and a read.</li>
</ul>
<h2 id="tar-storage">Tar Storage</h2>
<p>The tape archive format (<strong>tar</strong>) is surprisingly similar to the Haystack volume. While tar files don’t implement a superblock, each file entry is stored at a 512-byte
aligned offset, and each file includes its own metadata header. This format allows us to calculate the offset of each file within the archive.</p>
<p>Here’s a hexdump of a simple test.tar archive containing two files: a.txt and b.txt.</p>
<p><img alt="Hexdump Tarfile" loading="lazy" src="/articles/storage/tar_objectstore/assets/hexdump.png#center"></p>
<p>In this example:</p>
<ul>
<li>a.txt contains the string &ldquo;foo\n&rdquo;, and b.txt contains &ldquo;bar\n&rdquo;.</li>
<li>Each file is preceded by a 512-byte header containing metadata like filename, permissions, and ownership.</li>
<li>Since a.txt is only 4 bytes long, it’s followed by null padding to align the next file (b.txt) to the 512-byte boundary.</li>
<li>The offset for b.txt starts at 0x400 (1024 bytes), which is a clean 512-byte multiple.</li>
</ul>
<p>Although tar uses more padding than Haystack (which aligns to 8-byte offsets), its fixed alignment still enables efficient offset tracking and data retrieval. Once the
byte offsets of each file are known, accessing a file is just a matter of seeking to the right position and reading the data.</p>
<p>Tar also provides nice recovery properties:</p>
<ul>
<li>An index of offsets can always be created by reading the tar file and recording the header positions as offsets.</li>
<li>Because this is a standard tar file, common tools like tar and cpio can extract the objects directly without the need for custom tooling.</li>
</ul>
<h2 id="python-prototype">Python Prototype</h2>
<p>Tar archives are typically read sequentially from start to finish. But if we build an index of byte offsets, we can enable random access to individual files.
Let’s explore this with a prototype in Python using the test.tar archive shown in the earlier hexdump. A copy of the archive can be downloaded
from <a href="./assets/test.tar">here</a>.</p>
<p>We have two options for building this prototype:</p>
<ul>
<li>The hard way, by manually parsing byte offsets directly from the tar header.</li>
</ul>
<p><img alt="Screenshot of byte offsets" loading="lazy" src="/articles/storage/tar_objectstore/assets/the_hard_way.png"></p>
<ul>
<li>The batteries-included way, using Python’s built-in <strong>tarfile</strong> module to extract header information cleanly.</li>
</ul>
<p>If you’re curious, fields and byte-offsets within file headers are listed
in <a href="(https://cgit.git.savannah.gnu.org/cgit/tar.git/tree/src/tar.h#n24)">GNU&rsquo;s tar header definition</a>.</p>
<p><img alt="Screenshot of the struct" loading="lazy" src="/articles/storage/tar_objectstore/assets/header_struct.png"></p>
<p>Here’s an example of the batteries-included approach using the <strong>tarfile</strong> module. I’ll scan the archive, read each file’s size and data offset, and store that in a dictionary:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env python3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tarfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ARCHIVE_FILE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;test.tar&#34;</span>
</span></span><span style="display:flex;"><span>BYTE_ALIGNMENT <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_header</span>(archive: str) <span style="color:#f92672">-&gt;</span> Dict:
</span></span><span style="display:flex;"><span>    entities <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>    header_offset <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(header_offset)
</span></span><span style="display:flex;"><span>            header <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(BYTE_ALIGNMENT)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> header <span style="color:#f92672">==</span> <span style="color:#e6db74">b</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\0</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">*</span> BYTE_ALIGNMENT:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>  <span style="color:#75715e"># End of archive, trailer will contain two 512-byte blocks of zeros</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                tarinfo <span style="color:#f92672">=</span> tarfile<span style="color:#f92672">.</span>TarInfo<span style="color:#f92672">.</span>frombuf(header, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>, errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;surrogateescape&#34;</span>)
</span></span><span style="display:flex;"><span>                file_name <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>name
</span></span><span style="display:flex;"><span>                file_size <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>size
</span></span><span style="display:flex;"><span>                data_offset <span style="color:#f92672">=</span> header_offset <span style="color:#f92672">+</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>                entities[file_name]<span style="color:#f92672">.</span>append([file_size, data_offset])
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error parsing header at offset </span><span style="color:#e6db74">{</span>header_offset<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>e<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            padding <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>ceil(file_size <span style="color:#f92672">/</span> BYTE_ALIGNMENT) <span style="color:#f92672">*</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>            header_offset <span style="color:#f92672">+=</span> BYTE_ALIGNMENT <span style="color:#f92672">+</span> padding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> entities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar_data <span style="color:#f92672">=</span> read_header(ARCHIVE_FILE)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> file_name, attributes <span style="color:#f92672">in</span> tar_data<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> attribute <span style="color:#f92672">in</span> attributes:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;filename: </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;10</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> attributes: file_size: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> data_offset: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Example output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% python offsets.py
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">512</span>   
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">13</span>     data_offset: <span style="color:#ae81ff">2560</span>  
</span></span><span style="display:flex;"><span>filename: b.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">1536</span>  
</span></span></code></pre></div><p>Notice that a.txt appears twice, each with a different file size and offset. This is expected. It’s possible to append files to a tar archive using <strong>tar -rf</strong>.
When a file is re-added, it becomes the newer version.</p>
<p>In our example archive file, <strong>a.txt</strong> was modified and appended, producing two versions in the archive. Traditional tar extraction reads from the beginning and
overwrites earlier entries as it encounters newer ones. But by having an index of offsets, I can seek directly to either version and extract it manually.</p>
<p>Here’s a helper function to extract a specific version of a file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_file</span>(archive: str, file_name: str, offset: int, read_bytes: int):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(offset)
</span></span><span style="display:flex;"><span>            data <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(read_bytes)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74">@</span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> out:
</span></span><span style="display:flex;"><span>                out<span style="color:#f92672">.</span>write(data)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error extracting </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74"> at offset: </span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Add the following lines in main to extract both versions of <strong>a.txt</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">2560</span>, <span style="color:#ae81ff">13</span>)
</span></span></code></pre></div><p>And the result:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ls -latr a.txt@*
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff   <span style="color:#ae81ff">4</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000200
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff  <span style="color:#ae81ff">13</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000a00
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000200
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000a00
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>fooooooo
</span></span></code></pre></div><p>This demonstrates simple object versioning using nothing more than tar’s existing append behavior and a bit of byte-level introspection.</p>
<h2 id="trade-offs-and-limitations">Trade-Offs and Limitations</h2>
<p>As with Haystack, there&rsquo;s not an efficient way to delete content from a tar archive without rewriting the entire file. Instead, deletion requires marking entries
as removed in the offsets database. Unlike Haystack which has explicit flags in its header, tar headers offer no such field. Meaning if we lose the index, we
can no longer distinguish active content from deleted entries by scanning the archive.</p>
<p>The data removal limitation also contributes to archive fragmentation. Until a process rewrites the archive to remove tombstoned data, deleted files remain in place,
consuming storage.</p>
<p>Another trade-off lies in tar&rsquo;s alignment strategy, both headers and data are aligned to 512-byte blocks. In typical usage, tar archives are compressed, which
minimizes the overhead of null padding. But for this design to support random access, the archive must remain uncompressed. Filesystems like ZFS and Btrfs can
apply transparent compression at the block level, but relying on underlying filesystem isn&rsquo;t ideal for portability. Haystack uses 8-byte alignment, which results
in less padding and more efficient use of space.</p>
<p>Also worth noting, my prototype doesn’t implement any kind of write locking. If this were used in a concurrent setting like a web application storing
assets, appends would require locking the archive to prevent corruption.</p>
<h2 id="future-opportunities">Future Opportunities</h2>
<p>Sharding across multiple archive files per bucket (directory) would be one enhancement. It would allow for round-robin writes with multiple appenders,
improving concurrency. Using multiple archive files per bucket also provides a mechanism to cap archive file sizes.</p>
<p>A mechanism for tombstoning files within an archive is also needed. As seen in the earlier hexdump, it might be possible to repurpose an existing header field to mark
content as deleted.  This would allow the offsets database to be reconstructed later, even after a crash or loss of metadata. Another idea is to write custom metadata
into the unused space within the 512-byte header block.  Whether this breaks compatibility with standard tar utilities remains an open question.</p>
<p>Compression and encryption are also worth exploring. Because the prototype seeks directly to file offsets and reads raw byte ranges, it’s feasible to compress file
content before appending it to the archive. Retrieval would involve decompressing on the fly after seeking to the file location within the archive. Similarly,
data-at-rest encryption could be supported by encrypting file contents during the write path and decrypting during reads. This allows per-object confidentiality
without relying on full-disk encryption or underlying filesystem support.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>It&rsquo;s oddly satisfying to bend old standards to new purposes, like using the tar format as the basis of an object store.  Putting this post together
has been a reminder on the types of challenges distributed file systems create when separating metadata from the data.  Simple things like marking
a file as deleted become complicated.</p>
<p>Let me know if this topic is interesting or you have follow-up suggestions.  I can be reached at <a href="https://bsky.app/profile/af9.us">Bluesky</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Virtual Router Lab on macOS with QEMU</title>
      <link>https://amf3.github.io/articles/virtualization/macos_qemu_networks/</link>
      <pubDate>Wed, 14 May 2025 00:00:00 +0000</pubDate>
      <guid>https://amf3.github.io/articles/virtualization/macos_qemu_networks/</guid>
      <description>Debugging macOS QEMU networking with unified logging and lightweight Linux VMs</description>
      <content:encoded><![CDATA[<p><a href="https://github.com/utmapp/UTM">UTM</a> and <a href="https://canonical.com/multipass">Multipass</a> are great apps for virtualization on macOS.<br>
But I wanted a lighter-weight approach by invoking QEMU directly.  Which meant I needed to understand how QEMU&rsquo;s networking options interact
with the <code>vmnet</code> virtualization API on macOS.</p>
<p>This becomes especially important when dealing with VM-to-VM connections, network isolation, and bridging on macOS.</p>
<p>In this post, I&rsquo;ll walk through creating a simple QEMU-based networking lab.</p>
<ul>
<li>Set up RouterOS and Alpine Linux VMs using QEMU on macOS</li>
<li>Connect VMs with Apple&rsquo;s Hypervisor <code>vmnet</code> networking APIs</li>
<li>Use unified logging to troubleshoot QEMU network issues on macOS</li>
</ul>
<h2 id="lab-setup-overview">Lab Setup Overview</h2>
<p>The network diagram shows the network topology used in this lab.  Both VMs run on on the
same macOS host and connected to virtual network interfaces using QEMU&rsquo;s support for Apple&rsquo;s <strong>vmnet</strong> virtualization API.</p>
<p>The RouterOS VM has two virtual network interfaces, which allows it to route traffic between the Alpine Linux VM and the physical local area network.</p>
<p><img alt="Network Diagram" loading="lazy" src="/articles/virtualization/macos_qemu_networks/assets/Network.png#center"></p>
<h2 id="qemu-networking-on-macos">QEMU Networking on macOS</h2>
<p>Let&rsquo;s review the <strong>vmnet.shared</strong> and <strong>vmnet.host</strong> labels in the Network1 and Network2 boxes.</p>
<ul>
<li>
<p><a href="https://www.qemu.org/docs/master/interop/qemu-qmp-ref.html#object-QMP-net.NetdevVmnetSharedOptions"><strong>vmnet.shared</strong></a>: Allows traffic from the VM to reach the Internet using a built-in network address translation (NAT) feature. This is similar to how UTM’s &ldquo;shared network&rdquo; mode works.</p>
</li>
<li>
<p><a href="https://www.qemu.org/docs/master/interop/qemu-qmp-ref.html#object-QMP-net.NetdevVmnetHostOptions"><strong>vmnet.host</strong></a>: Traffic can only reach the macOS host and other VMs on the same host-mode network. This mode <strong>does not</strong> provide Internet access.</p>
</li>
</ul>
<p>Since the Alpine Linux VM is only connected to the <code>vmnet.host</code> network, and that network cannot reach the Internet, we know the RouterOS VM must be acting as the gateway. It routes traffic between <code>Network2</code> (host-only) and <code>Network1</code> (shared). You can confirm this by watching interface packet counts on RouterOS.</p>
<h3 id="triple-nat">Triple NAT!</h3>
<p>As a fun side note, traffic from the Alpine VM to the Internet passes through <strong>three layers of NAT</strong>:</p>
<ol>
<li><strong>RouterOS VM NAT:</strong> Alpine’s traffic is translated as it passes through RouterOS (ether2 → ether1).</li>
<li><strong>macOS vmnet NAT:</strong> <code>vmnet0</code> (shared mode) applies another layer of NAT as it exits to the host’s physical LAN.</li>
<li><strong>Physical Router NAT:</strong> Finally, the home router applies NAT before sending packets to the Internet.</li>
</ol>
<h3 id="other-qemu-network-backends">Other QEMU Network Backends</h3>
<p>To see a complete list of network backends supported by QEMU:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cmd" data-lang="cmd"><span style="display:flex;"><span>%  qemu-system-x86_64 -netdev help  
</span></span><span style="display:flex;"><span>Available netdev backend types:
</span></span><span style="display:flex;"><span>socket
</span></span><span style="display:flex;"><span>stream
</span></span><span style="display:flex;"><span>dgram
</span></span><span style="display:flex;"><span>hubport
</span></span><span style="display:flex;"><span>tap
</span></span><span style="display:flex;"><span>user
</span></span><span style="display:flex;"><span>vde
</span></span><span style="display:flex;"><span>bridge
</span></span><span style="display:flex;"><span>vhost-user
</span></span><span style="display:flex;"><span>vmnet-host
</span></span><span style="display:flex;"><span>vmnet-shared
</span></span></code></pre></div><p>A few notes about QEMU network backends:</p>
<p><strong>socket</strong> and <strong>user</strong>: Built into QEMU and don’t require elevated privileges. Great for quick VMs, but they don’t behave like traditional network bridges. You can’t easily interconnect multiple VMs.</p>
<p><strong>tap</strong>: Closer to a traditional bridged network and supports full traffic pass-through. However, it requires setup outside of QEMU and isn’t available on macOS, since tap interfaces depend on kernel extensions (which Apple no longer supports).</p>
<p><strong>vmnet</strong>: The backend is macOS-native and works out of the box with Apple’s Hypervisor Framework.  It lets QEMU manage the bridge interfaces directly so no extra tooling is needed. Win!</p>
<h2 id="creating-the-vms">Creating the VMs</h2>
<h3 id="routeros-vm">RouterOS VM</h3>
<p>RouterOS &ldquo;Cloud Hosted Router&rdquo; (CHR) is a commercial product with a &ldquo;free to use&rdquo; license that limits upload speed to 1 Mbps. While a paid license is available
to remove the upload limit, the restriction doesn&rsquo;t prevent me from validating changes before deploying them to physical networks.</p>
<p>One can download the CHR image from <a href="https://mikrotik.com/download">MikroTik’s download page</a>. I used the stable 7.x version and chose the <strong>Raw disk image</strong> — which is x86 (not ARM).</p>
<blockquote>
<p>💡 In hindsight, the ARM image might be more appropriate for Apple Silicon, but the x86 image works fine.</p></blockquote>
<p><img alt="RouterOS download page with &lsquo;Cloud Hosted Router&rsquo; and &lsquo;Raw disk image&rsquo; highlighted" loading="lazy" src="/articles/virtualization/macos_qemu_networks/assets/routerOS-dl-screenshot.png#center"></p>
<hr>
<p>First, convert the raw image to <code>qcow2</code> format. This allows snapshotting the VM, making it easy to roll back from bad config changes.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> % qemu-img convert -f raw -O qcow2 chr-7.18.2.img chr-7.18.2.qcow2
</span></span><span style="display:flex;"><span> % qemu-img snapshot -c original_image chr-7.18.2.qcow2
</span></span><span style="display:flex;"><span> % qemu-img info chr-7.18.2.qcow2 
</span></span><span style="display:flex;"><span>image: chr-7.18.2.qcow2
</span></span><span style="display:flex;"><span>file format: qcow2
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">128</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">134217728</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: 44.2 MiB
</span></span><span style="display:flex;"><span>cluster_size: <span style="color:#ae81ff">65536</span>
</span></span><span style="display:flex;"><span>Snapshot list:
</span></span><span style="display:flex;"><span>ID      TAG               VM_SIZE                DATE        VM_CLOCK     ICOUNT
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>       original_image        <span style="color:#ae81ff">0</span> B 2025-05-08 22:40:36  0000:00:00.000          <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>Format specific information:
</span></span><span style="display:flex;"><span>    compat: 1.1
</span></span><span style="display:flex;"><span>    compression type: zlib
</span></span><span style="display:flex;"><span>    lazy refcounts: false
</span></span><span style="display:flex;"><span>    refcount bits: <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>    corrupt: false
</span></span><span style="display:flex;"><span>    extended l2: false
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: chr-7.18.2.qcow2
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: 44.2 MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">46333952</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: 44.2 MiB
</span></span></code></pre></div><p>Now, start the RouterOS VM and create the two virtual networks with QEMU.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo qemu-system-x86_64  -m <span style="color:#ae81ff">2048</span> -smp cpus<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> -serial mon:stdio  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -device virtio-scsi-pci,id<span style="color:#f92672">=</span>scsi0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -drive file<span style="color:#f92672">=</span>./chr-7.18.2.qcow2,if<span style="color:#f92672">=</span>none,format<span style="color:#f92672">=</span>qcow2,discard<span style="color:#f92672">=</span>unmap,id<span style="color:#f92672">=</span>hda <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -device scsi-hd,drive<span style="color:#f92672">=</span>hda,bus<span style="color:#f92672">=</span>scsi0.0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -device virtio-net-pci,netdev<span style="color:#f92672">=</span>net1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -netdev vmnet-shared,id<span style="color:#f92672">=</span>net1,start-address<span style="color:#f92672">=</span>172.16.0.1,end-address<span style="color:#f92672">=</span>172.31.255.254,subnet-mask<span style="color:#f92672">=</span>255.240.0.0 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -device virtio-net-pci,netdev<span style="color:#f92672">=</span>net2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -netdev vmnet-host,id<span style="color:#f92672">=</span>net2,start-address<span style="color:#f92672">=</span>192.168.2.1,end-address<span style="color:#f92672">=</span>192.168.2.254,subnet-mask<span style="color:#f92672">=</span>255.255.255.0,net-uuid<span style="color:#f92672">=</span>154780B0-F499-4968-9B20-E58C02FDF5FB
</span></span></code></pre></div><ul>
<li>Uses sudo to create vmnet interfaces (required on macOS).</li>
<li>Allocates 2 GB of RAM and 4 vCPUs.</li>
<li>Opens a serial console in the terminal (handy for copy/paste).</li>
<li>Attaches two network devices:
<ul>
<li>vmnet-shared for simulated external Internet.</li>
<li>vmnet-host for internal traffic (private LAN).</li>
</ul>
</li>
<li>IP ranges must follow <a href="https://datatracker.ietf.org/doc/html/rfc1918">RFC 1918</a> allocation.</li>
<li>Using net-uuid disables the macOS DHCP server for the vmnet-host network.
<ul>
<li>Required as we want the RouterOS VM to respond with DHCP replies for vmnet-host traffic.</li>
<li>Generate the UUID with <strong>/usr/bin/uuidgen</strong>.</li>
</ul>
</li>
</ul>
<p>Once RouterOS boots, log in with username <strong>admin</strong> and press <strong>Enter</strong> for a blank password. You’ll be prompted to set a new one.</p>
<p>To list interfaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /interface print 
</span></span><span style="display:flex;"><span>Flags: R - RUNNING
</span></span><span style="display:flex;"><span>Columns: NAME, TYPE, ACTUAL-MTU, MAC-ADDRESS
</span></span><span style="display:flex;"><span><span style="color:#75715e">#   NAME    TYPE      ACTUAL-MTU  MAC-ADDRESS      </span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span> R ether1  ether           <span style="color:#ae81ff">1500</span>  52:54:00:12:34:56
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span> R ether2  ether           <span style="color:#ae81ff">1500</span>  52:54:00:12:34:57
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> R lo      loopback       <span style="color:#ae81ff">65536</span>  00:00:00:00:00:00
</span></span></code></pre></div><p>To check assigned IPs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip/address print
</span></span><span style="display:flex;"><span>Flags: D - DYNAMIC
</span></span><span style="display:flex;"><span>Columns: ADDRESS, NETWORK, INTERFACE
</span></span><span style="display:flex;"><span><span style="color:#75715e">#   ADDRESS        NETWORK     INTERFACE</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">0</span> D 172.16.0.2/12  172.16.0.0  ether1
</span></span></code></pre></div><p>Only one IP is listed — why?  The vmnet-shared interface (ether1) has DHCP enabled by Apple’s Hypervisor framework. RouterOS sends a DHCP
request and gets an IP, similar to how a home router works. Meanwhile, vmnet-host has DHCP disabled, so we must assign a static IP to ether2
on the router.</p>
<h4 id="minimal-configuration-steps">Minimal Configuration Steps</h4>
<p>Here are the minimum configuration steps to route traffic:</p>
<ul>
<li>assign a static IP on ether2</li>
<li>create a dhcpd server</li>
<li>enable NAT</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip address add address<span style="color:#f92672">=</span>192.168.2.1/24 interface<span style="color:#f92672">=</span>ether2 network<span style="color:#f92672">=</span>192.168.2.0
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip pool add name<span style="color:#f92672">=</span>dhcp ranges<span style="color:#f92672">=</span>192.168.2.50-192.168.2.100
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip dhcp-server add address-pool<span style="color:#f92672">=</span>dhcp interface<span style="color:#f92672">=</span>ether2 lease-time<span style="color:#f92672">=</span>1h name<span style="color:#f92672">=</span>defconf
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip dhcp-server network add address<span style="color:#f92672">=</span>192.168.2.0/24 comment<span style="color:#f92672">=</span>defconf dns-server<span style="color:#f92672">=</span>172.16.0.1,1.1.1.1 gateway<span style="color:#f92672">=</span>192.168.2.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /ip firewall nat add action<span style="color:#f92672">=</span>masquerade chain<span style="color:#f92672">=</span>srcnat out-interface<span style="color:#f92672">=</span>ether1
</span></span></code></pre></div><blockquote>
<p>⚠️ The example does not set any firewall rules. Use it as a starting point only.</p></blockquote>
<p>To gracefully shutdown the router</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#f92672">[</span>admin@MikroTik<span style="color:#f92672">]</span> &gt; /system shutdown
</span></span></code></pre></div><p>Answer y when prompted. Or, leave the router running. It will be used again shortly.</p>
<h3 id="alpine-linux-vm">Alpine Linux VM</h3>
<p>An Alpine ISO needs to be downloaded and installed onto a virtual hard disk.  I recommend using the <strong>user</strong> network mentioned earlier
for the install as additional packages will need to be downloaded from the Internet.  The standard x86_64 image can be retrieved from the Alpine Linux <a href="https://alpinelinux.org/downloads/">downloads page</a>.</p>
<p>Create a disk image to install the OS to with the qemu-img command.  The options will use the qcow2 format with a max size of 2GB.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img create -f qcow2 alpine_disk.qcow2 2G
</span></span></code></pre></div><p>Next step is to start a VM that boots from the Alpine ISO and connects to the Internet with the user network.  Because versions change, be
sure to replace the ISO filename in the <strong>-cdrom</strong> option with the one that was downloaded.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-system-x86_64  -m <span style="color:#ae81ff">2048</span> -smp cpus<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> -serial stdio  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -boot once<span style="color:#f92672">=</span>d <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -cdrom ./alpine-standard-3.21.2-x86_64.iso <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -hda ./alpine_disk.qcow2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -net nic,model<span style="color:#f92672">=</span>virtio -net user
</span></span></code></pre></div><p>Once the VM has started, login as &ldquo;root&rdquo; and hit Enter for the empty password.  Next run <strong>setup-alpine</strong> and follow the prompts.
Here are suggested answers to some of the prompts:</p>
<ul>
<li>Select <strong>dhcp</strong> for eth0.</li>
<li>Choose <strong>chrony</strong> as the network time server.</li>
<li>Accept the default of <strong>1</strong> when asked which &ldquo;apk-mirror&rdquo; to use.</li>
<li>When prompted about the install disk, select <strong>sda</strong>.</li>
<li>Answer <strong>sys</strong> to the &ldquo;how would you like to use it&rdquo; question.</li>
</ul>
<p>When the installation script is complete, type <strong>reboot</strong> and use the new root password set during the install.  With
the <code>-boot once=d</code> option, the VM will skip the ISO and boot directly from the newly installed virtual disk.</p>
<p>Log in as root and install the dig and curl commands.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cmd" data-lang="cmd"><span style="display:flex;"><span># apk add bind-tools curl ca-certificates
</span></span></code></pre></div><p>When the package install has completed, gracefully shutdown the VM with <strong>poweroff</strong> command.</p>
<h2 id="testing-the-nat-setup">Testing the NAT Setup</h2>
<p>Check that the RouterOS VM is still running in the other terminal. It&rsquo;s acting as the NAT gateway for the Alpine VM and must be
active for Internet access to work.  Then connect the new Alpine Linux VM to Network2 (vmnet-host) with this QEMU command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% sudo qemu-system-x86_64  -m <span style="color:#ae81ff">2048</span> -smp cpus<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> -serial mon:stdio  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        -boot c <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        -hda alpine_disk.qcow2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        -device virtio-net-pci,netdev<span style="color:#f92672">=</span>net2 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>        -netdev vmnet-host,id<span style="color:#f92672">=</span>net2,start-address<span style="color:#f92672">=</span>192.168.2.1,end-address<span style="color:#f92672">=</span>192.168.2.254,subnet-mask<span style="color:#f92672">=</span>255.255.255.0,net-uuid<span style="color:#f92672">=</span>154780B0-F499-4968-9B20-E58C02FDF5FB
</span></span></code></pre></div><p>Log into the Alpine VM and verify it can reach the Internet.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>myvm:~$ ip addr show eth0         <span style="color:#75715e"># Confirm the IP is in the 192.168.2.x network range</span>
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    inet 192.168.2.100/24 scope global eth0
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>myvm:~$ ip route show             <span style="color:#75715e"># Confirm the default route is 192.168.2.1</span>
</span></span><span style="display:flex;"><span>default via 192.168.2.1 dev eth0  metric <span style="color:#ae81ff">202</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>myvm:~$ cat /etc/resolv.conf      <span style="color:#75715e"># Confirm the DNS servers were set</span>
</span></span><span style="display:flex;"><span>nameserver 172.16.0.1
</span></span><span style="display:flex;"><span>nameserver 1.1.1.1
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>myvm:~$ ping -qc <span style="color:#ae81ff">3</span> 1.1.1.1        <span style="color:#75715e"># test ping to 1.1.1.1 on the Internet</span>
</span></span><span style="display:flex;"><span>PING 1.1.1.1 <span style="color:#f92672">(</span>1.1.1.1<span style="color:#f92672">)</span>: <span style="color:#ae81ff">56</span> data bytes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>--- 1.1.1.1 ping statistics ---
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3</span> packets transmitted, <span style="color:#ae81ff">3</span> packets received, 0% packet loss
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>myvm:~$ dig @172.16.0.1 -t a +short www.github.com  <span style="color:#75715e"># test vmnet name resolution works </span>
</span></span><span style="display:flex;"><span>github.com.
</span></span><span style="display:flex;"><span>140.82.116.4
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>myvm:~$ curl -I https://www.github.com              <span style="color:#75715e"># test that I can fetch a webpage</span>
</span></span><span style="display:flex;"><span>HTTP/2 <span style="color:#ae81ff">301</span> 
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>If all of the above checks pass, your Alpine VM is correctly NAT&rsquo;d through the RouterOS VM and can reach the Internet.</p>
<h2 id="troubleshooting--gotchas">Troubleshooting &amp; Gotchas</h2>
<h3 id="debugging-with-unified-logging">Debugging with Unified Logging</h3>
<p>macOS logs a large volume of network-related events, and it can be tricky to isolate the relevant ones. Fortunately, the <code>log show</code>
and <code>log collect</code> tools make it easier to filter and investigate.</p>
<p>Start by capturing a snapshot of system logs around the time your VMs are active:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% mkdir ./log_archive
</span></span><span style="display:flex;"><span>% ./start_lab <span style="color:#75715e"># start the VMs with a shell script</span>
</span></span><span style="display:flex;"><span>% sudo log collect --output ./log_archive --last 3m  <span style="color:#75715e"># capture the previous 3 minutes of log events.</span>
</span></span></code></pre></div><p>This captures the previous 3 minutes of logs and stores them in a binary archive. Then query the relevant subsystem:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% log show --archive log_archive/system_logs.logarchive --predicate <span style="color:#e6db74">&#39;subsystem == &#34;com.apple.NetworkSharing&#34;&#39;</span>  
</span></span></code></pre></div><p>I found the <code>subsystem == &quot;com.apple.NetworkSharing&quot;</code> query provided the most useful results.  Using other filters like <code>subsystem == &quot;com.apple.network&quot;</code>
or <code>process == &quot;qemu-system-x86_64&quot;</code> included many unrelated events and were a little overwhelming.  This screenshot shows the networks being created
when the VMs are started and then torn down when the VMs are stopped.</p>
<p><img alt="network_events" loading="lazy" src="/articles/virtualization/macos_qemu_networks/assets/network_events.png"></p>
<h3 id="packet-captures-with-wireshark-or-tcpdump">Packet Captures with Wireshark or tcpdump</h3>
<p>Because QEMU uses virtual network interfaces, it&rsquo;s possible to monitor VM traffic directly from macOS using tools like tcpdump or Wireshark.  Use the
<code>ifconfig</code> command to identify which vmenet interfaces are active and which bridge they are mapped to.</p>
<p><img alt="ifconfig output" loading="lazy" src="/articles/virtualization/macos_qemu_networks/assets/ifconfig_out.png"></p>
<p>Using Wireshark on the correct interface reveals detailed traffic flows. In this example capture, we see:</p>
<ul>
<li>ICMP ping requests to the router’s external interface</li>
<li>A DNS lookup for speedtest.net</li>
<li>An HTTP GET request initiating the speed test</li>
</ul>
<p><img alt="wireshark output" loading="lazy" src="/articles/virtualization/macos_qemu_networks/assets/wireshark.png"></p>
<h3 id="other-quirks">Other quirks</h3>
<p>I wrote a simple C program to list the interfaces created by QEMU but ran into permission errors.  It turns out that macOS protects the vmnet APIs
behind System Integrity Protection (SIP). To access them, binaries must be code-signed with a full Apple Developer certificate,
which I don’t have (and didn’t want to pay for). Fortunately, macOS’s unified logging system provided helpful insight.</p>
<hr>
<p>Another issue I encountered was with subnet settings in the router configs. At one point, I accidentally assigned 192.168.2.1/32 instead
of 192.168.2.1/24 to the host-only interface on the RouterOS VM. This broke routing for the two VMs, blocking the Alpine VM from reaching the Internet.</p>
<hr>
<p>At first glance QEMU’s socket-based networking may seem like a good replacement for bridged networking. It’s built into QEMU and doesn’t require
elevated privileges. So why not use it? It turns out that socket networking is intended for point-to-point communication between specific QEMU instances, like
TCP client/server setups. Socket networking doesn’t support general Ethernet bridging or broadcast traffic. For a more flexible setup that allows multiple VMs
to communicate freely (and with the host), you still need tap or vmnet.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Running QEMU directly on macOS isn’t the most beginner-friendly experience, but it was a great learning opportunity.  I have a better
appreciation for why tools like UTM or Multipass exist as wrappers around QEMU.</p>
<p>Next time I might try replacing the x86 images with arm64 images to explore the performance differences.  I&rsquo;m also considering writing my own QEMU wrapper,
partly for fun and partly for continuious integration purposes.</p>
<p>If you enjoyed this or want to follow along with future experiments, follow me on <a href="https://bsky.app/profile/af9.us">Bluesky</a>. Thanks for reading!</p>
]]></content:encoded>
    </item>
    <item>
      <title>Tips for working with qemu images</title>
      <link>https://amf3.github.io/articles/virtualization/qemuimage_tips/</link>
      <pubDate>Sun, 06 Apr 2025 07:41:29 -0400</pubDate>
      <guid>https://amf3.github.io/articles/virtualization/qemuimage_tips/</guid>
      <description>QEMU image file tips and tricks</description>
      <content:encoded><![CDATA[<p>QEMU uses files to emulate storage devices, and the features available
depend on how those files are created.  While QEMU can emulate disks from Parallels and VirtualBox, I’m going to
focus on the formats most commonly used in automation and scripting, <strong>raw</strong> and <strong>qcow2</strong>.</p>
<p>The default format is raw and raw offers the fewest features.  It&rsquo;s just plain storage.  The other format qcow2
supports compression, snapshots, and copy-on-write in addition to storage.</p>
<h2 id="raw-format">Raw Format</h2>
<p>Creating a raw disk with qemu-img is similar to using dd to create a block-based file. One can see this with
the output of <strong>qemu-img info</strong>.</p>
<p>Here I create two storage devices, one with qemu-img which defaults to the raw format and another with the
dd command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img create my_disk.img +1m         
</span></span><span style="display:flex;"><span>Formatting <span style="color:#e6db74">&#39;my_disk.img&#39;</span>, fmt<span style="color:#f92672">=</span>raw size<span style="color:#f92672">=</span><span style="color:#ae81ff">1048576</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% dd <span style="color:#66d9ef">if</span><span style="color:#f92672">=</span>/dev/zero of<span style="color:#f92672">=</span>my_block.file count<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span> bs<span style="color:#f92672">=</span>1m
</span></span><span style="display:flex;"><span>1+0 records in
</span></span><span style="display:flex;"><span>1+0 records out
</span></span></code></pre></div><p>Now let&rsquo;s use <strong>qemu-img info</strong> to confirm there&rsquo;s no difference between the two files.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img info my_disk.img  
</span></span><span style="display:flex;"><span>image: my_disk.img
</span></span><span style="display:flex;"><span>file format: raw
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">1</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">1</span> MiB
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: my_disk.img
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: <span style="color:#ae81ff">1</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: <span style="color:#ae81ff">1</span> MiB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% qemu-img info my_block.file 
</span></span><span style="display:flex;"><span>image: my_block.file
</span></span><span style="display:flex;"><span>file format: raw
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">1</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">1</span> MiB
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: my_block.file
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: <span style="color:#ae81ff">1</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: <span style="color:#ae81ff">1</span> MiB
</span></span></code></pre></div><h2 id="qcow2-format">Qcow2 Format</h2>
<p>Creating a disk in <strong>qcow2</strong> format enables zlib compression by default.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img create -f qcow2 my_disk.img 1M 
</span></span><span style="display:flex;"><span>Formatting <span style="color:#e6db74">&#39;my_disk.img&#39;</span>, fmt<span style="color:#f92672">=</span>qcow2 cluster_size<span style="color:#f92672">=</span><span style="color:#ae81ff">65536</span> extended_l2<span style="color:#f92672">=</span>off compression_type<span style="color:#f92672">=</span>zlib size<span style="color:#f92672">=</span><span style="color:#ae81ff">1048576</span> lazy_refcounts<span style="color:#f92672">=</span>off refcount_bits<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% qemu-img info my_disk.img 
</span></span><span style="display:flex;"><span>image: my_disk.img
</span></span><span style="display:flex;"><span>file format: qcow2
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">1</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">196</span> KiB
</span></span><span style="display:flex;"><span>cluster_size: <span style="color:#ae81ff">65536</span>
</span></span><span style="display:flex;"><span>Format specific information:
</span></span><span style="display:flex;"><span>    compat: 1.1
</span></span><span style="display:flex;"><span>    compression type: zlib
</span></span><span style="display:flex;"><span>    lazy refcounts: false
</span></span><span style="display:flex;"><span>    refcount bits: <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>    corrupt: false
</span></span><span style="display:flex;"><span>    extended l2: false
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: my_disk.img
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: <span style="color:#ae81ff">192</span> KiB <span style="color:#f92672">(</span><span style="color:#ae81ff">197120</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: <span style="color:#ae81ff">196</span> KiB
</span></span></code></pre></div><h1 id="tip-one---resize-an-image-file">Tip One - Resize an image file</h1>
<p>It&rsquo;s possible to grow or shrink a QEMU storage device.  Think of this as expanding the physical SSD itself, not the filesystem
that sits on it.  <strong>Important,</strong> when shrinking a image with negative values,
<strong>always shrink the filesystem first</strong> using resize2fs before running qemu-img resize <strong>or risk data corruption.</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img resize my_disk.img +1m  
</span></span><span style="display:flex;"><span>Image resized.
</span></span></code></pre></div><p>When inspecting the new disk image, we see the new capacity is 2MB but the file size on disk is under 200KB.  This is because qcow2 supports
copy-on-write and compression.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img info my_disk.img
</span></span><span style="display:flex;"><span>image: my_disk.img
</span></span><span style="display:flex;"><span>file format: qcow2
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">2</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">2097152</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">196</span> KiB
</span></span><span style="display:flex;"><span>cluster_size: <span style="color:#ae81ff">65536</span>
</span></span><span style="display:flex;"><span>Format specific information:
</span></span><span style="display:flex;"><span>    compat: 1.1
</span></span><span style="display:flex;"><span>    compression type: zlib
</span></span><span style="display:flex;"><span>    lazy refcounts: false
</span></span><span style="display:flex;"><span>    refcount bits: <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>    corrupt: false
</span></span><span style="display:flex;"><span>    extended l2: false
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: my_disk.img
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: <span style="color:#ae81ff">192</span> KiB <span style="color:#f92672">(</span><span style="color:#ae81ff">197120</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: <span style="color:#ae81ff">196</span> KiB
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% ls -lh my_disk.img 
</span></span><span style="display:flex;"><span>-rw-r--r--  <span style="color:#ae81ff">1</span> adam  staff   192K Apr  <span style="color:#ae81ff">6</span> 10:19 my_disk.img
</span></span></code></pre></div><p>If I were to resize a QEMU storage file formatted as raw, the file size on disk of 2MB matches the image capacity of 2MB as raw
doesn&rsquo;t support compression or copy-on-write.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img create raw_disk.img +2m
</span></span><span style="display:flex;"><span>Formatting <span style="color:#e6db74">&#39;raw_disk.img&#39;</span>, fmt<span style="color:#f92672">=</span>raw size<span style="color:#f92672">=</span><span style="color:#ae81ff">2097152</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% ls -lh raw_disk.img 
</span></span><span style="display:flex;"><span>-rw-r--r--  <span style="color:#ae81ff">1</span> adam  staff   2.0M Apr  <span style="color:#ae81ff">6</span> 10:22 raw_disk.img
</span></span></code></pre></div><h1 id="tip-two---snapshots">Tip Two - Snapshots</h1>
<p>Snapshots are supported with qcow2 devices.  These are handy for creating a base disk image that&rsquo;s shareable and later modified
for other purposes.  Snapshots also make a great backup point before making image changes.</p>
<p>To create a snapshot named &ldquo;my_first_snapshot&rdquo; inside an existing qcow2 image.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img snapshot -c my_first_snapshot my_disk.img 
</span></span></code></pre></div><p>To list existing snapshots</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img snapshot -l my_disk.img 
</span></span><span style="display:flex;"><span>Snapshot list:
</span></span><span style="display:flex;"><span>ID      TAG               VM_SIZE                DATE        VM_CLOCK     ICOUNT
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>       my_first_snapshot      <span style="color:#ae81ff">0</span> B 2025-04-06 10:37:07  0000:00:00.000          <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>To revert or &ldquo;apply&rdquo; a snapshot</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img snapshot -a my_first_snapshot my_disk.img 
</span></span></code></pre></div><p>To delete a snapshot from a file</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img snapshot -d my_first_snapshot my_disk.img 
</span></span></code></pre></div><h1 id="tip-three---modify-a-qemu-image">Tip Three - Modify a QEMU image</h1>
<p>While many online guides suggest using the Network Block Device (NBD) kernel driver in Linux to mount and modify QEMU images, I
use a different process that also works on MacOS.  My preferred method is to boot a VM using QEMU and attaching the image as a data drive.</p>
<p>This example uses the <a href="https://dl-cdn.alpinelinux.org/alpine/v3.21/releases/x86_64/alpine-extended-3.21.3-x86_64.iso">extended x86_64 Alpine Linux ISO</a>
and a QEMU command that mounts the image as a data drive.  The Alpine extended ISO lets you log in as root with an empty password,
which makes quick edits easy.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#75715e">#/bin/sh</span>
</span></span><span style="display:flex;"><span>qemu-system-x86_64 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -m 2G -smp cpus<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> -serial stdio <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -boot once<span style="color:#f92672">=</span>d  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -drive file<span style="color:#f92672">=</span>./my_disk.img,format<span style="color:#f92672">=</span>qcow2,media<span style="color:#f92672">=</span>disk,cache<span style="color:#f92672">=</span>unsafe <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -drive file<span style="color:#f92672">=</span>./alpine-extended-3.21.2-x86_64.iso,format<span style="color:#f92672">=</span>raw,media<span style="color:#f92672">=</span>cdrom <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>  -nic user,model<span style="color:#f92672">=</span>virtio-net-pci,hostfwd<span style="color:#f92672">=</span>tcp::2222-:22
</span></span></code></pre></div><p>Once logged in, you&rsquo;ll see the QEMU file we want to modify listed as /dev/sda.  The device hasn&rsquo;t been formatted with a filesystem, but if
one were present it could be mounted within the VM, files edited within the image, and then unmounted.</p>
<h1 id="tip-four---transfer-a-qemu-image-to-bare-metal">Tip Four - Transfer a QEMU image to bare-metal</h1>
<p>It&rsquo;s possible to use a QEMU image with bare-metal by converting it to <strong>raw</strong> format.  Use the following to convert the image from qcow2 to raw.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img convert -f qcow2 -O raw my_disk.img raw_disk.img
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% qemu-img info raw_disk.img 
</span></span><span style="display:flex;"><span>image: raw_disk.img
</span></span><span style="display:flex;"><span>file format: raw
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">10</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">10485760</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">10</span> MiB
</span></span><span style="display:flex;"><span>Child node <span style="color:#e6db74">&#39;/file&#39;</span>:
</span></span><span style="display:flex;"><span>    filename: raw_disk.img
</span></span><span style="display:flex;"><span>    protocol type: file
</span></span><span style="display:flex;"><span>    file length: <span style="color:#ae81ff">10</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">10485760</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    disk size: <span style="color:#ae81ff">10</span> MiB
</span></span></code></pre></div><p>Once we have the raw image, the <strong>dd</strong> command can be used to write the data to either a USB stick or physical SSD.  To avoid
any destructive commands let&rsquo;s pretend raw_disk2.img represents /dev/sdc, your verified USB thumb drive.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% dd <span style="color:#66d9ef">if</span><span style="color:#f92672">=</span>raw_disk.img of<span style="color:#f92672">=</span>raw_disk2.img bs<span style="color:#f92672">=</span>1m 
</span></span><span style="display:flex;"><span>10+0 records in
</span></span><span style="display:flex;"><span>10+0 records out
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10485760</span> bytes transferred in 0.006266 secs <span style="color:#f92672">(</span><span style="color:#ae81ff">1673437600</span> bytes/sec<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>Because our raw file is only 10MB in size, only 10MB will be used on the thumb drive.  This is where follow up tools like LVM or
resize2fs will extend the filesystem to fill the entire thumb drive.  Tools used for expansion depends on how the filesystem was created.</p>
<h1 id="putting-it-all-together">Putting it all together</h1>
<p>Enough with the documentation, let&rsquo;s put it into practice with a real use case.  Presume that after reading my <a href="../../../articles/cloudinit/intro/">cloud-init
tutorials</a> you wish to modify the <a href="https://dl-cdn.alpinelinux.org/alpine/v3.21/releases/cloud/nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2">Alpine Linux cloud-init image</a> before installation.</p>
<p>We can see the downloaded file is a qcow2 image with a capacity of 200Mb from <strong>qemu-img info</strong>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> % qemu-img info nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2 
</span></span><span style="display:flex;"><span>image: nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2
</span></span><span style="display:flex;"><span>file format: qcow2
</span></span><span style="display:flex;"><span>virtual size: <span style="color:#ae81ff">200</span> MiB <span style="color:#f92672">(</span><span style="color:#ae81ff">209715200</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">181</span> MiB
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>As we want to install our java app into the installer, we need to add space to the image with <strong>qemu-img resize</strong>.  But first,
let’s create a snapshot. That way, if we make a mistake, we won’t need to re-download the cloud-init image.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img snapshot -c no_modifications nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% qemu-img resize nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2 +800M
</span></span><span style="display:flex;"><span>Image resized.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> % qemu-img info nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2        
</span></span><span style="display:flex;"><span>image: nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2
</span></span><span style="display:flex;"><span>file format: qcow2
</span></span><span style="display:flex;"><span>virtual size: 0.977 GiB <span style="color:#f92672">(</span><span style="color:#ae81ff">1048576000</span> bytes<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>disk size: <span style="color:#ae81ff">197</span> MiB
</span></span><span style="display:flex;"><span>cluster_size: <span style="color:#ae81ff">65536</span>
</span></span><span style="display:flex;"><span>Snapshot list:
</span></span><span style="display:flex;"><span>ID      TAG               VM_SIZE                DATE        VM_CLOCK     ICOUNT
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">1</span>       no_modifications      <span style="color:#ae81ff">0</span> B 2025-04-06 15:23:50  0000:00:00.000          <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>Format specific information:
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><p>I&rsquo;m still using the Alpine extended ISO to boot the VM. Alpine cloud images require setup for ssh key authentication to login and an
empty root password is much easier to use.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-system-x86_64 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -m 2G -smp cpus<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span> -serial stdio <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -boot once<span style="color:#f92672">=</span>d  <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -drive file<span style="color:#f92672">=</span>./nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2,format<span style="color:#f92672">=</span>qcow2,media<span style="color:#f92672">=</span>disk,cache<span style="color:#f92672">=</span>unsafe <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -drive file<span style="color:#f92672">=</span>./alpine-extended-3.21.2-x86_64.iso,format<span style="color:#f92672">=</span>raw,media<span style="color:#f92672">=</span>cdrom <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>    -nic user,model<span style="color:#f92672">=</span>virtio-net-pci,hostfwd<span style="color:#f92672">=</span>tcp::2222-:22
</span></span></code></pre></div><p>Login as root and mount the disk device under /mnt</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>localhost:~# mount /dev/sda /mnt 
</span></span><span style="display:flex;"><span>localhost:~# ls /mnt
</span></span><span style="display:flex;"><span>bin         home        mnt         run         tmp
</span></span><span style="display:flex;"><span>boot        lib         opt         sbin        usr
</span></span><span style="display:flex;"><span>dev         lost+found  proc        srv         var
</span></span><span style="display:flex;"><span>etc         media       root        sys
</span></span></code></pre></div><p>Then make changes to the cloud image, unmount the filesystem and you&rsquo;re done.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>localhost:~# echo <span style="color:#e6db74">&#34;Adam Faris was here&#34;</span> &gt; /mnt/etc/motd 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>localhost:~# cat /mnt/etc/motd 
</span></span><span style="display:flex;"><span>Adam Faris was here
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>localhost:~# umount /mnt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>localhost:~# poweroff
</span></span></code></pre></div><p>Finally, convert our modified cloud image from qcow2 format to raw format, then use dd to write the raw image to a USB device.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>% qemu-img convert -f qcow2 -O nocloud_alpine-3.21.2-x86_64-bios-cloudinit-r0.qcow2 alpine_cloudinit.raw
</span></span><span style="display:flex;"><span>% dd <span style="color:#66d9ef">if</span><span style="color:#f92672">=</span>alpine_cloudinit.raw bs<span style="color:#f92672">=</span>1m of<span style="color:#f92672">=</span>/dev/...
</span></span></code></pre></div><p>With the modified image written to the USB device, you can now boot a physical machine from it. Thanks for sticking with me until
the end. If you find this content useful, follow me on <a href="https://@amf3.bsky.social">BlueSky social</a> for future announcements.</p>
]]></content:encoded>
    </item>
    <item>
      <title>cloud-init troubleshooting</title>
      <link>https://amf3.github.io/articles/cloudinit/troubleshooting/</link>
      <pubDate>Fri, 21 Mar 2025 16:28:54 -0400</pubDate>
      <guid>https://amf3.github.io/articles/cloudinit/troubleshooting/</guid>
      <description>A simple workflow in resolving cloud-init deployment problems.</description>
      <content:encoded><![CDATA[<p>I previously wrote an <a href="../../../articles/cloudinit/intro/">introduction</a> to cloud-init. I&rsquo;d like to now follow up with a discussion on
troubleshooting. cloud-init failures on remote hosts can be challenging. Depending on the failure point, cloud-init may or may not
provide clear error indicators.  These are methods I use during provisioning issues related to cloud-init.</p>
<h1 id="understanding-cloud-init-execution-stages">Understanding cloud-init execution stages</h1>
<p>Before continuing, let&rsquo;s cover some background.  cloud-init follows
<a href="https://cloudinit.readthedocs.io/en/latest/explanation/boot.html">five stages</a> during boot which run sequentially. If
a stage completes, output will contain a status that can be used to verify that stage was successful.</p>
<p><strong>Detect stage:</strong> The init system is responsible for calling
<a href="https://github.com/canonical/cloud-init/blob/main/tools/ds-identify">ds_identify</a> to determine whether cloud-init
should run.  With systemd hosts, this is implemented as a systemd generator.</p>
<p><strong>Local stage:</strong> Identifies local resources that are available without network access. Configures networking, which if unsuccessful
falls back to DHCP.</p>
<p><strong>Network stage:</strong> Retrieves user-data, sets up disk partitions, and mounts the filesystem.  When complete, serial console or SSH access
should become available.</p>
<p><strong>Config stage:</strong> Runs configuration modules and executes commands specified in user-data.</p>
<p><strong>Final stage:</strong> Installs packages, applies configuration management plugins like puppet or chef, and runs user or vendor defined scripts.</p>
<h1 id="checking-stage-status">Checking Stage Status</h1>
<p>The <strong>status</strong> submenu from the cloud-init command provides a method of checking each stage for errors.  In this
example I intentionally mistyped a schema key name that should be <code>passwd</code> as <code>password</code>.  Output shows the failure
occurred during the init stage &amp; provides a suggestion on how to resolve it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cloud-init status --format json
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;extended_status&#34;</span>: <span style="color:#e6db74">&#34;degraded done&#34;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;init&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;errors&#34;</span>: <span style="color:#f92672">[]</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;finished&#34;</span>: 6.52,
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;recoverable_errors&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;WARNING&#34;</span>: <span style="color:#f92672">[</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;cloud-config failed schema validation! You may run &#39;sudo cloud-init schema --system&#39; to check the details.&#34;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>,
</span></span><span style="display:flex;"><span>...
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;status&#34;</span>: <span style="color:#e6db74">&#34;done&#34;</span>
</span></span></code></pre></div><h1 id="checking-logs-for-errors">Checking logs for Errors</h1>
<p>When the issue is not obvious, there logs are available for further examination.</p>
<ul>
<li>/var/log/cloud-init.log  (execution details and errors)</li>
<li>/var/log/cloud-init-output.log  (captured output from executed commands)</li>
<li>/run/cloud-init/result.json  (summary of execution status)</li>
</ul>
<p>Example log output from cloud-init.log indicating a schema validation failure.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>2025-03-18 11:46:41,379 - schema.py<span style="color:#f92672">[</span>WARNING<span style="color:#f92672">]</span>: cloud-config failed schema validation! You may run <span style="color:#e6db74">&#39;sudo cloud-init schema --system&#39;</span> to check the details.
</span></span></code></pre></div><h1 id="debugging-user-data-issues">Debugging User-Data Issues</h1>
<p>cloud-init has a defined schema and it’s possible to validate user-data content with the <strong>schema</strong> submenu.
To troubleshoot a possible schema issue on a remote host where a YAML key named <code>passwd</code> was mistyped as <code>password</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo cloud-init schema --system
</span></span><span style="display:flex;"><span>Found cloud-config data types: user-data, vendor-data, network-config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>1. user-data at /var/lib/cloud/instances/docker-demo/cloud-config.txt:
</span></span><span style="display:flex;"><span>  Invalid user-data /var/lib/cloud/instances/docker-demo/cloud-config.txt
</span></span><span style="display:flex;"><span>  Error: Cloud config schema errors: users.0: Additional properties are not allowed <span style="color:#f92672">(</span><span style="color:#e6db74">&#39;password&#39;</span> was unexpected<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>…
</span></span><span style="display:flex;"><span>Error: Invalid schema: user-data
</span></span></code></pre></div><p>To test changes made to user-data content prior to provisioning: <code>cloud-init schema -c “my_user_data_file.yaml”</code>.</p>
<p>For timeout issues in user or vendor scripts, <code>cloud-init analyze</code> will print execution times which pinpoint delays.</p>
<h1 id="common-failure-scenarios-and-fixes">Common Failure Scenarios and Fixes</h1>
<p>A typical source of failures is from syntax errors in the user-data file.  As already mentioned, <code>cloud-init schema</code> will
show schema issues in user-data.  Manually check for typos within the values in user-data. A mistyped value is
still a string and can pass the schema validation.</p>
<p>Another possible issue is misconfigured network settings preventing package installation.  Ensure package mirrors are reachable
and contain the package.  The <strong>cloud-init-output.log</strong> file can show additional hints related to package failures.  If SSH is unavailable,
try accessing the instance over the instance&rsquo;s serial console.</p>
<p>Check for missing or incorrectly set permissions on scripts.</p>
<p>Use <code>cloud-init analyze show</code> to help in identifying long-running stages.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ cloud-init analyze show
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>-- Boot Record <span style="color:#ae81ff">01</span> --
</span></span><span style="display:flex;"><span>The total time elapsed since completing an event is printed after the <span style="color:#e6db74">&#34;@&#34;</span> character.
</span></span><span style="display:flex;"><span>The time the event takes is printed after the <span style="color:#e6db74">&#34;+&#34;</span> character.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Starting stage: init-local
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;no cache found @00.00100s +00.00000s
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;found local data from DataSourceNoCloud @00.00400s +00.01500s
</span></span><span style="display:flex;"><span>Finished stage: <span style="color:#f92672">(</span>init-local<span style="color:#f92672">)</span> 00.28900 seconds
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Starting stage: init-network
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;restored from cache with run check: DataSourceNoCloud <span style="color:#f92672">[</span>seed<span style="color:#f92672">=</span>/dev/vda<span style="color:#f92672">]</span> @02.56800s +00.00100s
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;setting up datasource @02.57600s +00.00000s
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;reading and applying user-data @02.58000s +00.00200s
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;reading and applying vendor-data @02.58200s +00.00200s
</span></span><span style="display:flex;"><span>|<span style="color:#e6db74">`</span>-&gt;reading and applying vendor-data2 @02.58400s +00.00000s
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h1 id="recovery-and-re-runs">Recovery and Re-Runs</h1>
<p>Additional steps are needed after modifying user-data files on the failed instance. When cloud-init runs, output is
cached to disk.  If the cache exists on reboot, cloud-init will not run again.  To clean cached instance data,
run <code>cloud-init clean --logs</code> and reboot the instance.</p>
<p>Issues with a specific module can be exposed by using <code>cloud-init single</code>.  This could be useful when
troubleshooting user or vendor scripts.  Module names can be found with <code>grep &quot;Running module&quot; /var/log/cloud-init.log</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>$ sudo cloud-init single --name set_passwords
</span></span><span style="display:flex;"><span>Cloud-init v. 24.4.1-0ubuntu0~24.04.1 running <span style="color:#e6db74">&#39;single&#39;</span> at Fri, <span style="color:#ae81ff">21</span> Mar <span style="color:#ae81ff">2025</span> 20:45:47 +0000. Up 16145.16 seconds.
</span></span></code></pre></div><p>When using the <strong>single</strong> submenu, it won&rsquo;t necessarily fix dependencies unless those are also explicitly re-triggered.  It&rsquo;s best
to reprovision the instance after troubleshooting any failed modules.</p>
<h1 id="takeaways">Takeaways</h1>
<p>There’s no simple fix for understanding why instance provisioning with cloud-init failed.  That’s why I’m
closing with a checklist.</p>
<ul>
<li>Check cloud-init status
<ul>
<li>Use <code>cloud-init status --long</code> (or &ndash;json) for execution state</li>
<li>Use <code>cloud-init analyze</code> for timing analysis</li>
</ul>
</li>
<li>Inspect logs for errors
<ul>
<li>/var/log/cloud-init.log: Shows errors and execution order</li>
<li>/var/log/cloud-init-output.log: contains command output</li>
</ul>
</li>
<li>Validate user-data input
<ul>
<li><code>cloud-init schema</code> to validate syntax</li>
<li>Ensure values are correct and not only properly formatted YAML</li>
</ul>
</li>
<li>Check for missing dependencies or network issues
<ul>
<li>Ensure package mirrors are available and contain the necessary packages.</li>
<li>Verify custom scripts are executable.</li>
</ul>
</li>
<li>Re-run cloud-init if needed.
<ul>
<li>Clean logs and reset cloud-init: <code>cloud-init clean --logs</code> &amp;&amp; reboot</li>
<li>Manually rerun a failed module: <code>cloud-init single -n “some_module_name”</code></li>
</ul>
</li>
</ul>
<p>Happy provisioning, and follow me on <a href="https://bsky.app/profile/af9.us">Bluesky</a> if you find content like this interesting.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Unattended Ubuntu Installs - Virtual Machines to Bare-Metal</title>
      <link>https://amf3.github.io/articles/cloudinit/autoinstall/</link>
      <pubDate>Mon, 03 Mar 2025 23:07:23 -0800</pubDate>
      <guid>https://amf3.github.io/articles/cloudinit/autoinstall/</guid>
      <description>Using cloud-init to deploy Linux on either bare-metal or virtual machines</description>
      <content:encoded><![CDATA[<p>In a <a href="../../../articles/cloudinit/intro/">previous post</a>, I discussed using cloud-init and Multipass as a method of provisioning
virtual machines on a local computer with a cloud-like API.  Today I am going
to dive deeper with Ubuntu and how their autoinstall API can simplify on-premise host provisioning.</p>
<p><a href="https://canonical-subiquity.readthedocs-hosted.com/en/latest/intro-to-autoinstall.html">autoinstall</a>
is a tool that allows for unattended installations of Ubuntu, ensuring consistency, reporducibility, and providing automation
across a fleet of hosts.  In this post I&rsquo;ll walk through an example of using autoinstall
to configure networking, local storage, and demonstrate shell command execution during provisioning.</p>
<h2 id="prerequisite">Prerequisite</h2>
<p>Because the final target is a bare-metal instance, I find it quicker to iterate &amp; test autoinstall changes with
QEMU on my macOS M2 laptop.  QEMU is a hardware emulator
which runs on Linux, macOS, &amp; Windows, allowing the emulation of different CPUs, network cards, or storage devices.
Instructions to <a href="https://www.qemu.org/download/#macos">install QEMU</a> can be found online.  For macOS, this can be as simple as
running <code>brew install qemu</code>.</p>
<p>Next we need the Ubuntu install media which can be downloaded
<a href="https://ubuntu.com/download/server">here</a>.</p>
<h3 id="qemu-overview">QEMU overview</h3>
<p>Let&rsquo;s get started by creating a virtual disk drive for installing Ubuntu.  This can be done with
<code>qemu-img create -f qcow2 virtual_disk.img 6G</code> which creates a 6GB virtual disk named
virtual_disk.img in the current directory.</p>
<p>In the example below, the <code>-boot once=d</code> option instructes QEMU to boot from the virtual CD-ROM on first startup. After which QEMU will
boot from the virtual disk. The other options initialize a 4 core CPU with 4GB of memory.  The <code>-net user,hostfwd</code> string will
port forward from localhost on the host system to port 22 on the virtual machine.  If additional port forwarding is needed, like testing
https traffic on port 443 of the VM, multiple hostfwd options seperated by commas can used.  Be sure to adjust the filename and path to the Ubuntu ISO
as needed.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">qemu-system-x86_64 -hda virtual_disk.img -boot once=d  -cdrom ./ubuntu-24.10-live-server-amd64.iso -m 4096 -smp cpus=4 -net nic,model=virtio -net user,hostfwd=tcp:127.0.0.1:2222-:22
</code></pre><h2 id="autoinstall">Autoinstall</h2>
<p>Autoinstall is included as part of the Ubuntu boot ISO and works with other provisioning tools from Canonical like
<a href="https://canonical-subiquity.readthedocs-hosted.com/en/latest/">Subiquity</a>,
<a href="https://curtin.readthedocs.io/en/latest/topics/overview.html">Curtin</a>, or <a href="https://cloudinit.readthedocs.io/en/latest/">cloud-init</a>.
When reading Autoinstall documentation, it&rsquo;s useful to know which tool is being used during each install stage as often those
options are passed to the underlying provisioning tool.</p>
<p>Like Kickstart for RHEL, Autoinstall is Ubuntu&rsquo;s answer to unattended
installations, and uses YAML files for data input.  Autoinstall uses default locations for finding the YAML files and locations
can also be specified in the GRUB menu when the instance boots.  Locations are specified as either a filepath or a URL.  I&rsquo;ll be
using a URL for the file locations.</p>
<p>Lets create the empty YAML files and use python to create a simple webserver to serve the files.  In another terminal type the following as the
webserver runs in the foreground.  Use cntl-c to terminate the python webserver when it&rsquo;s no longer needed.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">touch user-data meta-data network-config vendor-data
python3 -m http.server -b 127.0.0.1 -d $PWD 8080
</code></pre><p>Next start the virtual machine.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">qemu-system-x86_64 -hda virtual_disk.img -boot once=d  -cdrom ./ubuntu-24.10-live-server-amd64.iso -m 4096 -smp cpus=4 -net nic,model=virtio -net user,hostfwd=tcp:127.0.0.1:2222-:22
</code></pre><p>This will open a QEMU console window where we&rsquo;ll interact with the GRUB menu to specify the YAML file locations. Change focus to
the console window, highlight &ldquo;Try or Install Ubuntu Server&rdquo; and hit the <code>&quot;e&quot;</code> key to edit the grub menu.</p>
<p>On the line starting with “linux /casper/vmlinuz” add:  <code>autoinstall ds=nocloud\;s=http://10.0.2.2:8080/</code>  before
the three dashes.  The grub menu should look something like this when the edits are complete.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">linux   /casper/vmlinuz autoinstall ds=nocloud\;s=http://10.0.2.2:8080/ ---
initrd  /casper/initrd  
</code></pre><p>Exit grub and boot by following the on-screen instructions to hit F10 or cntl-x.  Watch the terminal running the python webserver and
requests for the autoinstall YAML files should be seen.  As they are empty config files, an interactive menu-driven session will present itself
in the QEMU console window.  To cancel the install, close the QEMU console window.</p>
<p>The GRUB modification tells autoinstall to use the
<a href="https://cloudinit.readthedocs.io/en/latest/reference/datasources/nocloud.html">nocloud</a> plugin from cloud-init to download
its configuration at the specified URL.  QEMU assigns the special IP address of <code>10.0.2.2</code> to the host system when using <code>-net user</code>.  This allows the
VM to reach services running on the host such as our local Python HTTP server and why autoinstall is able to download its configurations over HTTP.</p>
<p>The YAML block should be added to the user-data file that was created earlier.  The other files will remain empty.
The <a href="https://github.com/canonical/subiquity/blob/main/doc/howto/autoinstall-quickstart.rst">minimal config example</a> assigns a
hostname of my-qemu-vm, creates an admin account named ubuntu, and assigns the ubuntu user the password of abc123.<br>
It&rsquo;s possible to generate a different secure password hash with openssl, as shown in
this example: <code>echo abc123 |  openssl passwd -6 -stdin</code>.  Restart the QEMU VM so it boots from the
virtual CD-ROM and modify the GRUB menu so it loads the new config when the VM boots.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">identity</span>:
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">hostname</span>: <span style="color:#ae81ff">my-qemu-vm</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">username</span>: <span style="color:#ae81ff">ubuntu</span>
</span></span><span style="display:flex;"><span>     <span style="color:#f92672">password</span>: <span style="color:#ae81ff">$6$xK2amorOU9tK4jt4$zLA1RZUpo4CzyDBzPDHCT61FLOngjWpV7Q/BH9KieLsJ/VG8r/Y88YIMLIOL.vc4ZHees40IAqORxjqa7GKti/</span>
</span></span><span style="display:flex;"><span>     <span style="color:#75715e"># password is &#34;abc123&#34;</span>
</span></span></code></pre></div><p>Autoinstall will take several minutes to complete and will reboot when done.  In some stages autoinstall can look stuck in some stages.
Remember that Linux virtual consoles are available to inspect running processes.  Virtual consoles are accessible by typing alt + left/right
arrow key or using alt + F2 or alt + F3.  (Use the option key for alt when using a Mac keyboard.)  Eventually the VM will reboot and the login
prompt should be visible if everything went as expected.</p>
<p>Autoinstall has a list of defaults it uses when the option is present in the user-data file.  After logging into the QEMU instance, it&rsquo;s
possible to view the specified values from the user-data YAML file that have been merged into the defaults.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">sudo less /var/log/installer/autoinstall-user-data
</code></pre><p>Before continuing lets enable the ssh server, allow passwords for ssh login, and minimize the number of packages used during
the install.  Other options like locale or the keyboard setup can be found in the autoinstall-user-data file and added ot the example below.  Restarting
the QEMU VM and modifying the GRUB menu to reinstall the host OS is needed to apply the new changes to the YAML file.  Reinstalling
the OS also demonstrates the ease of initializing a system to a known state with autoinstall &amp; cloud-init configs.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">version</span>: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">identity</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">hostname</span>: <span style="color:#ae81ff">my-qemu-vm</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">username</span>: <span style="color:#ae81ff">ubuntu</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">password</span>: <span style="color:#ae81ff">$6$xK2amorOU9tK4jt4$zLA1RZUpo4CzyDBzPDHCT61FLOngjWpV7Q/BH9KieLsJ/VG8r/Y88YIMLIOL.vc4ZHees40IAqORxjqa7GKti/</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># password is &#34;abc123&#34;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">ssh</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Install SSH server and allow password logins</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">allow-pw</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">install-server</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">source</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># id can also be ubuntu-server </span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">id</span>: <span style="color:#ae81ff">ubuntu-server-minimal</span>
</span></span></code></pre></div><h3 id="networking">Networking</h3>
<p>Both autoinstall and cloud-init support a netplan-formatted network configuration, meaning the YAML network example will work with
either installer.</p>
<p>Network device names are different between distributions that use Systemd (Ubuntu, Fedora) vs OpenRC (Alpine).  Where OpenRC
will use easily found device names like &ldquo;eth0&rdquo;, or &ldquo;eth1&rdquo;,
<a href="https://www.freedesktop.org/software/systemd/man/latest/systemd.net-naming-scheme.html">Systemd</a> will use the PCI slot number.
A Systemd example might look like &ldquo;enp2s0&rdquo;, where &ldquo;en&rdquo; means ethernet, and &ldquo;p2s0&rdquo; is the
<a href="https://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/">physical PCI slot</a>.
This value will change based on which slot a PCI card is plugged into.  Luckily
<a href="https://canonical-subiquity.readthedocs-hosted.com/en/latest/reference/autoinstall-reference.html#network">autoinstall</a>
lets us wildcard the device names.</p>
<p>This network example will work with either OpenRC or Systemd device names.  It&rsquo;s similar to what&rsquo;s used by
<a href="https://git.launchpad.net/livecd-rootfs/tree/live-build/ubuntu-server/includes.chroot.ubuntu-server-minimal.ubuntu-server.installer/etc/cloud/cloud.cfg#n23">Ubuntu&rsquo;s LiveCD</a>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">network</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">version</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">ethernets</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">my-en-devices</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># This will match Systemd naming conventions for ethernet devices which start with &#34;en&#34; and set them to use DHCPv4</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;en*&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">dhcp4</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">my-eth-devices</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># This will match OpenRC naming conventions like &#34;eth0&#34;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;eth*&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># This will specify a static network address</span>
</span></span><span style="display:flex;"><span>          - <span style="color:#ae81ff">10.10.10.2</span><span style="color:#ae81ff">/24</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">nameservers</span>:
</span></span><span style="display:flex;"><span>          <span style="color:#75715e"># We can modify the DNS search path &amp; specify DNS name servers.</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">search</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#e6db74">&#34;mycompany.local&#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#f92672">addresses</span>:
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">10.10.10.253</span>
</span></span><span style="display:flex;"><span>            - <span style="color:#ae81ff">8.8.8.8</span>
</span></span></code></pre></div><h3 id="storage">Storage</h3>
<p>Configuring
<a href="https://canonical-subiquity.readthedocs-hosted.com/en/latest/reference/autoinstall-reference.html#storage">storage</a>
can be complex when configuring per partition byte offsets. Luckily we can provide a storage device name and let defaults
handle the details.  I&rsquo;ll show a basic lvm example but the other supported layouts are direct, and zfs.</p>
<p>Here we specify a LVM configuration with a sizing policy to use the entire disk for the logical volume.  If sizing-policy
were set to <code>scaled</code>, free space would be left on the storage device for things like snapshots or further expansion.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">layout</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lvm</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">sizing-policy</span>: <span style="color:#ae81ff">all</span>
</span></span></code></pre></div><p>Its possible to target a specific drive to wipe and install a new OS with a
<a href="https://canonical-subiquity.readthedocs-hosted.com/en/latest/reference/autoinstall-reference.html#disk-selection-extensions">match</a>
statement.  There are multiple ways to select a storage device, model name, serial number, path, whether
its rotational or not, or even big or little in size.  These values can be found in smartctl output, which
comes from the smartmontools package.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">ubuntu@my-qemu-vm:~$ sudo apt-get install -y smartmontools
... install stuff ...

ubuntu@my-qemu-vm:~$ sudo smartctl -i /dev/sda
smartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.11.0-18-generic] (local build)
Copyright (C) 2002-23, Bruce Allen, Christian Franke, www.smartmontools.org

=== START OF INFORMATION SECTION ===
Device Model:     QEMU HARDDISK
Serial Number:    QM00001
Firmware Version: 2.5+
User Capacity:    8,589,934,592 bytes [8.58 GB]
Sector Size:      512 bytes logical/physical
TRIM Command:     Available, deterministic
Device is:        Not in smartctl database 7.3/5528
ATA Version is:   ATA/ATAPI-7, ATA/ATAPI-5 published, ANSI NCITS 340-2000
Local Time is:    Tue Mar  4 05:45:56 2025 UTC
SMART support is: Available - device has SMART capability.
SMART support is: Enabled
</code></pre><p>If we wanted to match this disk by wild-carding the model name, we would use the following.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">layout</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lvm</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">sizing-policy</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">model</span>: <span style="color:#ae81ff">QEMU*</span>
</span></span></code></pre></div><p>Alternatively if our on-premise hardware instance had a 1GB SSD for the OS and a second 12GB spinning disk for data storage, we could
use a match with size <code>size: smallest</code> to install the OS on the 1GB disk.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">storage</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">layout</span>:
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">name</span>: <span style="color:#ae81ff">lvm</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">sizing-policy</span>: <span style="color:#ae81ff">all</span>
</span></span><span style="display:flex;"><span>         <span style="color:#f92672">match</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">size</span>: <span style="color:#ae81ff">smallest</span>
</span></span></code></pre></div><h3 id="commands">Commands</h3>
<p>Running arbitrary commands is possible when autoinstall runs.  Commands are specified as a list and run under &ldquo;sh -c&rdquo;.
Its  possible to specify if commands should run early in the autoinstall process, late, or when an error occurs.</p>
<p>For example we want to hit a web endpoint when the installer has completed.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">late-commands</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">curl -H &#39;Content-Type</span>: <span style="color:#ae81ff">application/json&#39; --data &#39;{&#34;host&#34;: &#34;&#39;$HOSTNAME&#39;&#34;}&#39; http://myapi.example.com/success</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">echo &#34;Install Success&#34;  &gt; /var/log/my.log</span>
</span></span></code></pre></div><p>To run a command before the autoinstall process runs, like downloading internal x509 certificates:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">early-commands</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">mkdir /etc/ssl/mycerts</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">wget -O /etc/ssl/mycerts/internal.pem &#34;http://x509api.example.com/certs/$HOSTNAME&#34;</span>
</span></span></code></pre></div><p>Or reporting an error when autoinstall fails</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">error-commands</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">echo &#34;Install failed&#34; &gt; /var/log/my.log</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#f92672">curl -H &#39;Content-Type</span>: <span style="color:#ae81ff">application/json&#39; --data &#39;{&#34;host&#34;: &#34;&#39;$HOSTNAME&#39;&#34;}&#39; http://myapi.example.com/failures</span>
</span></span></code></pre></div><h3 id="cloud-init">cloud-init</h3>
<p>It&rsquo;s possible to invoke cloud-init from autoinstall, allowing for additional functionality. This is done by placing
the cloud-init entries under a user-data key.  Here&rsquo;s a cloud-init example that installs a few packages.</p>
<p>cloud-init and
autoinstall sometimes perform similar tasks. When configuring a storage device with cloud-init, I found it was
better to use autoinstall as the cloud-init changes were overwritten.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">user-data</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">package_update</span>: <span style="color:#66d9ef">true</span>    <span style="color:#75715e"># update the list of available packages</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">package_upgrade</span>: <span style="color:#66d9ef">true</span>   <span style="color:#75715e"># upgrade currently installed packages.</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">packages</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">ca-certificates</span>
</span></span></code></pre></div><h3 id="other">Other</h3>
<p>It&rsquo;s possible to configure a local proxy for downloading software packages.  Running apt-cacher-ng as a package
proxy inside a docker container on my laptop helps when I&rsquo;m on a high latency Internet connection.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e">#cloud-config</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">autoinstall</span>:
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">proxy</span>: <span style="color:#ae81ff">http://10.0.2.2:3142</span>
</span></span></code></pre></div><h2 id="provision-a-physical-host">Provision a physical host</h2>
<p>A complete autoinstall user-data file can be downloaded from <a href="./assets/user-data">here</a>.  It contains all the examples listed in this post.</p>
<p>Provisioning a physical host is very similar to using QEMU. The only change is when starting the python
webserver.  Instead of python binding to 127.0.0.1, have it bind to all interfaces so configs can be downloaded
by remote hosts.</p>
<pre tabindex="0"><code class="language-code" data-lang="code">python3 -m http.server -d $PWD 8080
</code></pre><p>A USB thumb drive is needed to make the Ubuntu ISO available to the physical host; and a monitor &amp; keyboard are needed
to modify the GRUB menu when the on-premise hosts boots. When modifying the GRUB menu,
instead of using http://10.0.2.2 in the nocloud URL, specify the hostname of the host running the python webserver.  In my scenario, the hostname would
resolve to my personal laptop.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>By leveraging autoinstall, it&rsquo;s possible to reliably reproduce system setups, whether for virtual machines or bare-metal hosts.
In this post, autoinstall was explored as a method to streamline unattended provisioning for Ubuntu instances.  Using a QEMU-based test environment,
it was possible to quickly iterate on autoinstall configurations by modifying the GRUB menu to pull configuration files over HTTP.  The process demonstrated
how to format storage devices, set up networking, and run shell commands during installation.</p>
<p>Next steps?  If looking to extend this setup, consider integrating additional automation, such as PXE boot for network-based installs or using cloud-init to
interact with configuration management systems like Puppet or Chef.  If you have insights from your own experiences, feel free to share them
on <a href="https://bsky.app/profile/af9.us">Bluesky</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Getting started with cloud-init for unattended Linux deployments</title>
      <link>https://amf3.github.io/articles/cloudinit/intro/</link>
      <pubDate>Fri, 21 Feb 2025 23:06:35 -0800</pubDate>
      <guid>https://amf3.github.io/articles/cloudinit/intro/</guid>
      <description>An intro to using cloud-init for customizing both on-premise and cloud virtual machines</description>
      <content:encoded><![CDATA[<p>Cloud compute companies like GCP, AWS, or Azure offer a management API for allocating resources. In the on-premise space,
services such as Docker or Incus provide APIs for managing containers or virtual machines (VMs). But what about installing
the operating system (OS) on bare-metal hosts? What API exists for this task? This is where
<a href="https://github.com/canonical/cloud-init">cloud-init</a> enters the picture, providing the ability to provision VMs or
bare-metal hardware.</p>
<p>cloud-init is a useful tool that doesn&rsquo;t rely on network services like PXE as a dependency.  Its simplicity saves time by
removing the need to navigate OS installation menus, while ensuring user accounts and installed software packages are consistent
across hosts. So why should one bother using cloud-init if they are managing a single host at home? In the event
the OS needs to be reinstalled due to failure, cloud-init allows one to quickly restore the system to a known state.</p>
<p>This example will use cloud-init to configure a Personal Package Archive (PPA), install Docker, and create a user account inside a Ubuntu VM.</p>
<h2 id="prerequisite">Prerequisite</h2>
<p>I find that using cloud-init with Multipass is a easy way to get started.  Multipass is a virtual machine manager that
works with Linux, MacOS (arm &amp; intel), and Windows.  When launching a new VM, Multipass is capable of initializing the VM with cloud-init.
If Multipass isn&rsquo;t already installed, this link will provide instructions for installing
<a href="https://canonical.com/multipass/install">Multipass</a>.  For this cloud-init introduction, I&rsquo;m using Multipass on a M2 Macbook running MacOS Sequoia.</p>
<h2 id="cloud-init">cloud-init</h2>
<p>Like many infrastructure tools, the input data for cloud-init is a YAML file.  For specifics of this schema, consult the official cloud-init
<a href="https://cloudinit.readthedocs.io/en/latest/index.html">documentation</a>.  There one will find that cloud-init input file
will need to be <a href="https://cloudinit.readthedocs.io/en/latest/tutorial/qemu.html#define-the-configuration-data-files">prefixed</a> with <code>#cloud-config</code>.</p>
<h3 id="package-management">Package Management</h3>
<p>Lets get started with package management for our Multipass instance.  This section will show how to add an external PPA (software repository) to
the VM with cloud-init to provide additional software packages and define a list of software packages to be installed on the VM.</p>
<h4 id="add-external-ppa">Add External PPA</h4>
<p>Add the 3rd-party <a href="https://cloudinit.readthedocs.io/en/latest/reference/modules.html#apt-configure">PPA</a> provided by Docker, Inc.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># Add Docker&#39;s PPA for Ubuntu</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">apt</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">sources</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">docker.list</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># This snippet comes from https://stackoverflow.com/a/62540068</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">source</span>: <span style="color:#ae81ff">deb [arch=arm64] https://download.docker.com/linux/ubuntu $RELEASE stable</span>
</span></span><span style="display:flex;"><span>      <span style="color:#75715e"># Key ID can be found with “gpg --show-keys &lt;(curl -s https://download.docker.com/linux/ubuntu/gpg)”</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">keyid</span>: <span style="color:#ae81ff">9DC858229FC7DD38854AE2D88D81803C0EBFCD88 </span>
</span></span></code></pre></div><p>Should the GPG key ID for the Docker PPA change, I have left a comment above on how to find that value.<br>
This is how the GPG output appears in 2025.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ gpg --show-keys &lt;<span style="color:#f92672">(</span>curl -s https://download.docker.com/linux/ubuntu/gpg<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>pub   rsa4096 2017-02-22 <span style="color:#f92672">[</span>SCEA<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>      9DC858229FC7DD38854AE2D88D81803C0EBFCD88
</span></span><span style="display:flex;"><span>uid                      Docker Release <span style="color:#f92672">(</span>CE deb<span style="color:#f92672">)</span> &lt;docker@docker.com&gt;
</span></span><span style="display:flex;"><span>sub   rsa4096 2017-02-22 <span style="color:#f92672">[</span>S<span style="color:#f92672">]</span>
</span></span></code></pre></div><h4 id="define-package-list">Define Package List</h4>
<p>Specify a list of <a href="https://cloudinit.readthedocs.io/en/latest/reference/modules.html#package-update-upgrade-install">packages</a> to install.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># Update the list of packages available online</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">package_update</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Upgrade all installed packages</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">package_upgrade</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install docker &amp; other utilities</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">packages</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">apt-transport-https</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">ca-certificates</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">curl</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">gnupg-agent</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">software-properties-common</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">docker-ce</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">docker-ce-cli</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">containerd.io</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">docker-buildx-plugin</span>
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">docker-compose-plugin</span>
</span></span></code></pre></div><h3 id="user-management">User Management</h3>
<p>Here a new <a href="https://cloudinit.readthedocs.io/en/latest/reference/yaml_examples/user_groups.html">user</a> account is created and added
to the docker group with cloud-init.  Its likely our user will require both a password &amp; ssh key for remote access.  A public ssh key and a
password hash is needed for cloud-init input.</p>
<h4 id="secrets-generating-a-password-hash">Secrets: Generating a Password Hash</h4>
<p>To create a password hash, use the <code>mkpasswd</code> command from Ubuntu&rsquo;s whois package.  This example will
hash the weak password of &ldquo;abc123&rdquo; with the sha512 algorithm.  A password better than &ldquo;abc123&rdquo; should be used if following these examples.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ mkpasswd -m sha-512 <span style="color:#e6db74">&#34;abc123&#34;</span>
</span></span><span style="display:flex;"><span>$6$EkwQ38oDCPnJDuui$QKw3IISzY3emHXgJ/QHeEH8xyzGOKB3N6.bU/wAkwf4KDRsreB2iApa/EHULbunx6v9o9Q8foq4K.d8WtHukU/
</span></span></code></pre></div><p>As mkpasswd is specific to Linux and doesn&rsquo;t work with MacOS, one can alternatively use <code>openssl</code> to create a password hash.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ echo abc123 |  openssl passwd -6 -stdin  
</span></span><span style="display:flex;"><span>$6$tdPON3RwkVViXg41$4O9euMZeGFJQXgJ3bvP3YtVcCw9BwIMHLLkix1s/R7woSuAAFvWWtrqqQ.33ESzgcUi9/HdEwelqB9jJUIrpU0
</span></span></code></pre></div><h4 id="secrets-generating-a-ssh-public-private-key-pair">Secrets: Generating a SSH public private key pair</h4>
<p>To create a SSH key pair, use ssh-keygen: <code>ssh-keygen -t ed25519 -f ./docker_vm_key -C &quot;app@docker_vm&quot; -P abc123</code>.  This will create a public &amp; private
ssh key in the current directory, with the easily guessable passphrase of <code>abc123</code>.  Once again, use a better passphrase if following these examples.</p>
<h4 id="defining-the-user-account">Defining the User Account</h4>
<p>This defines an application account named &ldquo;app&rdquo;.  The <code>ssh_authorized_keys</code> value comes from the contents of docker_vm_key.pub.<br>
As a convenience, the <a href="./assets/docker_vm_key.pub">public</a> and <a href="./assets/docker_vm_key">private</a> ssh keys from this example are provided.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#75715e"># create the docker group</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">groups</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#ae81ff">docker</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">users</span>:
</span></span><span style="display:flex;"><span>  - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">app</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">groups</span>: [<span style="color:#ae81ff">docker, admin, users]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">gecos</span>: <span style="color:#ae81ff">Application User</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">shell</span>: <span style="color:#ae81ff">/bin/bash</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">lock_passwd</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">passwd</span>: <span style="color:#ae81ff">$6$tdPON3RwkVViXg41$4O9euMZeGFJQXgJ3bvP3YtVcCw9BwIMHLLkix1s/R7woSuAAFvWWtrqqQ.33ESzgcUi9/HdEwelqB9jJUIrpU0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">ssh_authorized_keys</span>:
</span></span><span style="display:flex;"><span>      - <span style="color:#ae81ff">ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHsPNGa1NJLd4edDLRI033Sw33Nkl6qO+52qNAhY556C app@docker_vm</span>
</span></span></code></pre></div><h3 id="putting-it-all-together">Putting it all together</h3>
<p>I&rsquo;ve combined the YAML snippets into a single file named docker-install.yaml which can be downloaded <a href="./assets/docker-install.yaml">here</a>.<br>
Run the following to see cloud-init in action. This will create a virtual machine with 2 virtual CPU cores, 2 GB of ram,
with a 4GB virtual disk using the LTS release of Ubuntu.  Depending on your Internet speed, this may take a few minutes as
you&rsquo;ll be downloading packages from the Internet.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>$ multipass launch -n docker-demo --cloud-init docker-install.yaml -c <span style="color:#ae81ff">2</span> -m 2G -d 4G lts
</span></span></code></pre></div><p>To find the new VM and access it over SSH with the private key so a docker command can be ran from a remote shell.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% mp list                                                                                                                             
</span></span><span style="display:flex;"><span>Name                    State             IPv4             Image
</span></span><span style="display:flex;"><span>docker-demo             Running           192.168.64.32    Ubuntu 24.04 LTS        
</span></span><span style="display:flex;"><span>                                          172.17.0.1     
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% ssh -l app -i ./docker_vm_key 192.168.64.32
</span></span><span style="display:flex;"><span> The authenticity of host <span style="color:#e6db74">&#39;192.168.64.32 (192.168.64.32)&#39;</span> can<span style="color:#e6db74">&#39;t be established.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> ED25519 key fingerprint is SHA256:EUqLjr9n9CyjKY6Y8EzNQGomeEtpePMFo5BXjO8YfHY.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> This key is not known by any other names.                                 
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74"> ...
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">app@docker-demo:~$ docker run hello-world
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">Unable to find image &#39;</span>hello-world:latest<span style="color:#960050;background-color:#1e0010">&#39;</span> locally
</span></span><span style="display:flex;"><span>latest: Pulling from library/hello-world
</span></span><span style="display:flex;"><span>c9c5fd25a1bd: Pull complete 
</span></span><span style="display:flex;"><span>Digest: sha256:e0b569a5163a5e6be84e210a2587e7d447e08f87a0e90798363fa44a0464a1e8
</span></span><span style="display:flex;"><span>Status: Downloaded newer image <span style="color:#66d9ef">for</span> hello-world:latest
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Hello from Docker!
</span></span><span style="display:flex;"><span>...
</span></span></code></pre></div><h2 id="conclusion">Conclusion</h2>
<p>Several cloud-init basics have been covered in this introduction. Like adding a PPA, installing software packages, and creating a user account.<br>
While I understand that installing Docker in my example might not represent the typical workflow.  Combining cloud-init concepts with Multipass
creates a local mini-cloud on my Macbook.  I can quickly iterate through cloud-init data file changes for other platforms like AWS or on-premise hardware.</p>
<p>cloud-init is capable of much more, like formatting hard drives or managing network interfaces.  These &amp; other topics will be covered in followups
which I will announce on <a href="https://bsky.app/profile/af9.us">Bluesky</a>.  Follow me for notifications of when its made available.  Otherwise,
try out these examples and let me know what works.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Contact</title>
      <link>https://amf3.github.io/about/contact/</link>
      <pubDate>Fri, 21 Feb 2025 22:58:02 -0700</pubDate>
      <guid>https://amf3.github.io/about/contact/</guid>
      <description>&lt;h3 id=&#34;how-to-get-in-touch&#34;&gt;How to get in touch&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/amf3&#34;&gt;https://github.com/amf3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;LinkedIn: &lt;a href=&#34;https://www.linkedin.com/in/adammfaris/&#34;&gt;https://www.linkedin.com/in/adammfaris/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;BlueSky Social: &lt;a href=&#34;https://@amf3.bsky.social&#34;&gt;https://@amf3.bsky.social&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      <content:encoded><![CDATA[<h3 id="how-to-get-in-touch">How to get in touch</h3>
<ul>
<li>GitHub: <a href="https://github.com/amf3">https://github.com/amf3</a></li>
<li>LinkedIn: <a href="https://www.linkedin.com/in/adammfaris/">https://www.linkedin.com/in/adammfaris/</a></li>
<li>BlueSky Social: <a href="https://@amf3.bsky.social">https://@amf3.bsky.social</a></li>
</ul>
]]></content:encoded>
    </item>
    <item>
      <title>Who, What, and Why</title>
      <link>https://amf3.github.io/about/about/</link>
      <pubDate>Fri, 21 Feb 2025 22:52:33 -0700</pubDate>
      <guid>https://amf3.github.io/about/about/</guid>
      <description>&lt;h3 id=&#34;who&#34;&gt;Who&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;m Adam Faris and my pronouns are he,him,his. Based in the San Francisco Bay Area, I have a strong background
in computer operations, with experience managing data processing platforms and working in large on-premise Linux
environments where languages like Java, Python, &amp;amp; Go come into play.&lt;/p&gt;
&lt;p&gt;Outside of &amp;ldquo;work,&amp;rdquo; you&amp;rsquo;ll find me in my vegetable garden or tackling DIY home repair projects – both of which
bring me a sense of accomplishment.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h3 id="who">Who</h3>
<p>I&rsquo;m Adam Faris and my pronouns are he,him,his. Based in the San Francisco Bay Area, I have a strong background
in computer operations, with experience managing data processing platforms and working in large on-premise Linux
environments where languages like Java, Python, &amp; Go come into play.</p>
<p>Outside of &ldquo;work,&rdquo; you&rsquo;ll find me in my vegetable garden or tackling DIY home repair projects – both of which
bring me a sense of accomplishment.</p>
<h3 id="what">What</h3>
<p>This is a place to share findings that could be useful or interesting to others.
It may also contain notes to myself as a reference in the future.  Topics will range from large
installation systems administration to home labs and embedded devices.</p>
<h3 id="why">Why</h3>
<p>I started working with data processing platforms in 2011.  It amazed me at how open
the data community was with sharing ideas and how quickly software changed for the better because of it.
With this site, I&rsquo;d like to carry on that tradition of sharing ideas and findings.</p>
<h3 id="how">How</h3>
<p>Feel free to follow me on <a href="https://@amf3.bsky.social">Bluesky</a> or subscribe to the <a href="https://amf3.github.io/index.xml">RSS feed</a>
if you want to be notified about updates to this site.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
