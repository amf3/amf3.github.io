<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Object Store on Adam Faris</title>
    <link>https://amf3.github.io/categories/object-store/</link>
    <description>Recent content in Object Store on Adam Faris</description>
    <generator>Hugo -- 0.150.1</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 May 2025 16:46:07 -0700</lastBuildDate>
    <atom:link href="https://amf3.github.io/categories/object-store/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Tar Files as Object Store Storage</title>
      <link>https://amf3.github.io/articles/storage/tar_objectstore/</link>
      <pubDate>Fri, 30 May 2025 16:46:07 -0700</pubDate>
      <guid>https://amf3.github.io/articles/storage/tar_objectstore/</guid>
      <description>Implementing Object Store storage with Log Structured Archives.</description>
      <content:encoded><![CDATA[<p>I&rsquo;m looking at how object storage systems manage data on disk. Especially the idea of using append only archives with an index for fast retrieveal.  While reading
Facebook&rsquo;s Haystack design, I noticed similarities to the tar file format and the potential to implement something similar at the local scale.</p>
<h2 id="haystack-overview">Haystack Overview</h2>
<p>There are several components mentioned in the original <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf">Haystack paper</a>, but at
the core is the Haystack Store, where end user image files are physically kept. Instead of writing files directly to the filesystem, images are appended
to a large file called a <strong>volume</strong>, which acts as an append-only archive. Each volume is typically capped at around 100 GB and is aligned to 8-byte
offsets.  Image files within this volume are referred to as <strong>needles</strong>.</p>
<p><img alt="Haystack Volume Description" loading="lazy" src="/articles/storage/tar_objectstore/assets/needles.png#center"></p>
<p>A volume begins with a superblock (the paper doesn’t describe this in detail), followed by the header for the first needle (file). Each needle within
the volume has its own header, containing metadata like file size, checksums, and flags. The flags field includes a bit to indicate deletion status.</p>
<p>Since the volume is append-only, deletions don’t reclaim space—they&rsquo;re simply marked as deleted in the needle’s header. A background process can later
compact the volume if needed. To keep track of where each needle is within the file, an in-memory index maps file IDs to byte offsets.</p>
<p>When a read request comes in, the Haystack Store performs a direct seek to the needle’s offset, verifies the flags to check if it&rsquo;s deleted, and returns
the data if is not tombstoned.  Deletions update both the in-memory index and the needle’s header to mark the entry as removed.</p>
<p>This model provides two big wins:</p>
<ul>
<li><strong>Storage efficiency:</strong> Small files, like 1 KB thumbnails, don’t waste space the way they would on a traditional filesystem with 4 KB blocks. Instead of allocating a full block per file, they&rsquo;re packed into a shared archive.</li>
<li><strong>Fast retrieval:</strong> There’s no need to scan directory structures or fetch inode metadata. With an open file handle to the volume and an in-memory index, reads are just a seek and a read.</li>
</ul>
<h2 id="tar-storage">Tar Storage</h2>
<p>The tape archive format (<strong>tar</strong>) is surprisingly similar to the Haystack volume. While tar files don’t implement a superblock, each file entry is stored at a 512-byte
aligned offset, and each file includes its own metadata header. This format allows us to calculate the offset of each file within the archive.</p>
<p>Here’s a hexdump of a simple test.tar archive containing two files: a.txt and b.txt.</p>
<p><img alt="Hexdump Tarfile" loading="lazy" src="/articles/storage/tar_objectstore/assets/hexdump.png#center"></p>
<p>In this example:</p>
<ul>
<li>a.txt contains the string &ldquo;foo\n&rdquo;, and b.txt contains &ldquo;bar\n&rdquo;.</li>
<li>Each file is preceded by a 512-byte header containing metadata like filename, permissions, and ownership.</li>
<li>Since a.txt is only 4 bytes long, it’s followed by null padding to align the next file (b.txt) to the 512-byte boundary.</li>
<li>The offset for b.txt starts at 0x400 (1024 bytes), which is a clean 512-byte multiple.</li>
</ul>
<p>Although tar uses more padding than Haystack (which aligns to 8-byte offsets), its fixed alignment still enables efficient offset tracking and data retrieval. Once the
byte offsets of each file are known, accessing a file is just a matter of seeking to the right position and reading the data.</p>
<p>Tar also provides nice recovery properties:</p>
<ul>
<li>An index of offsets can always be created by reading the tar file and recording the header positions as offsets.</li>
<li>Because this is a standard tar file, common tools like tar and cpio can extract the objects directly without the need for custom tooling.</li>
</ul>
<h2 id="python-prototype">Python Prototype</h2>
<p>Tar archives are typically read sequentially from start to finish. But if we build an index of byte offsets, we can enable random access to individual files.
Let’s explore this with a prototype in Python using the test.tar archive shown in the earlier hexdump. A copy of the archive can be downloaded
from <a href="./assets/test.tar">here</a>.</p>
<p>We have two options for building this prototype:</p>
<ul>
<li>The hard way, by manually parsing byte offsets directly from the tar header.</li>
</ul>
<p><img alt="Screenshot of byte offsets" loading="lazy" src="/articles/storage/tar_objectstore/assets/the_hard_way.png"></p>
<ul>
<li>The batteries-included way, using Python’s built-in <strong>tarfile</strong> module to extract header information cleanly.</li>
</ul>
<p>If you’re curious, fields and byte-offsets within file headers are listed
in <a href="(https://cgit.git.savannah.gnu.org/cgit/tar.git/tree/src/tar.h#n24)">GNU&rsquo;s tar header definition</a>.</p>
<p><img alt="Screenshot of the struct" loading="lazy" src="/articles/storage/tar_objectstore/assets/header_struct.png"></p>
<p>Here’s an example of the batteries-included approach using the <strong>tarfile</strong> module. I’ll scan the archive, read each file’s size and data offset, and store that in a dictionary:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env python3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tarfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ARCHIVE_FILE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;test.tar&#34;</span>
</span></span><span style="display:flex;"><span>BYTE_ALIGNMENT <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_header</span>(archive: str) <span style="color:#f92672">-&gt;</span> Dict:
</span></span><span style="display:flex;"><span>    entities <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>    header_offset <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(header_offset)
</span></span><span style="display:flex;"><span>            header <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(BYTE_ALIGNMENT)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> header <span style="color:#f92672">==</span> <span style="color:#e6db74">b</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\0</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">*</span> BYTE_ALIGNMENT:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>  <span style="color:#75715e"># End of archive, trailer will contain two 512-byte blocks of zeros</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                tarinfo <span style="color:#f92672">=</span> tarfile<span style="color:#f92672">.</span>TarInfo<span style="color:#f92672">.</span>frombuf(header, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>, errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;surrogateescape&#34;</span>)
</span></span><span style="display:flex;"><span>                file_name <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>name
</span></span><span style="display:flex;"><span>                file_size <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>size
</span></span><span style="display:flex;"><span>                data_offset <span style="color:#f92672">=</span> header_offset <span style="color:#f92672">+</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>                entities[file_name]<span style="color:#f92672">.</span>append([file_size, data_offset])
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error parsing header at offset </span><span style="color:#e6db74">{</span>header_offset<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>e<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            padding <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>ceil(file_size <span style="color:#f92672">/</span> BYTE_ALIGNMENT) <span style="color:#f92672">*</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>            header_offset <span style="color:#f92672">+=</span> BYTE_ALIGNMENT <span style="color:#f92672">+</span> padding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> entities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar_data <span style="color:#f92672">=</span> read_header(ARCHIVE_FILE)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> file_name, attributes <span style="color:#f92672">in</span> tar_data<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> attribute <span style="color:#f92672">in</span> attributes:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;filename: </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;10</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> attributes: file_size: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> data_offset: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Example output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% python offsets.py
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">512</span>   
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">13</span>     data_offset: <span style="color:#ae81ff">2560</span>  
</span></span><span style="display:flex;"><span>filename: b.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">1536</span>  
</span></span></code></pre></div><p>Notice that a.txt appears twice, each with a different file size and offset. This is expected. It’s possible to append files to a tar archive using <strong>tar -rf</strong>.
When a file is re-added, it becomes the newer version.</p>
<p>In our example archive file, <strong>a.txt</strong> was modified and appended, producing two versions in the archive. Traditional tar extraction reads from the beginning and
overwrites earlier entries as it encounters newer ones. But by having an index of offsets, I can seek directly to either version and extract it manually.</p>
<p>Here’s a helper function to extract a specific version of a file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_file</span>(archive: str, file_name: str, offset: int, read_bytes: int):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(offset)
</span></span><span style="display:flex;"><span>            data <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(read_bytes)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74">@</span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> out:
</span></span><span style="display:flex;"><span>                out<span style="color:#f92672">.</span>write(data)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error extracting </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74"> at offset: </span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Add the following lines in main to extract both versions of <strong>a.txt</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">2560</span>, <span style="color:#ae81ff">13</span>)
</span></span></code></pre></div><p>And the result:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ls -latr a.txt@*
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff   <span style="color:#ae81ff">4</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000200
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff  <span style="color:#ae81ff">13</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000a00
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000200
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000a00
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>fooooooo
</span></span></code></pre></div><p>This demonstrates simple object versioning using nothing more than tar’s existing append behavior and a bit of byte-level introspection.</p>
<h2 id="trade-offs-and-limitations">Trade-Offs and Limitations</h2>
<p>As with Haystack, there&rsquo;s not an efficient way to delete content from a tar archive without rewriting the entire file. Instead, deletion requires marking entries
as removed in the offsets database. Unlike Haystack which has explicit flags in its header, tar headers offer no such field. Meaning if we lose the index, we
can no longer distinguish active content from deleted entries by scanning the archive.</p>
<p>The data removal limitation also contributes to archive fragmentation. Until a process rewrites the archive to remove tombstoned data, deleted files remain in place,
consuming storage.</p>
<p>Another trade-off lies in tar&rsquo;s alignment strategy, both headers and data are aligned to 512-byte blocks. In typical usage, tar archives are compressed, which
minimizes the overhead of null padding. But for this design to support random access, the archive must remain uncompressed. Filesystems like ZFS and Btrfs can
apply transparent compression at the block level, but relying on underlying filesystem isn&rsquo;t ideal for portability. Haystack uses 8-byte alignment, which results
in less padding and more efficient use of space.</p>
<p>Also worth noting, my prototype doesn’t implement any kind of write locking. If this were used in a concurrent setting like a web application storing
assets, appends would require locking the archive to prevent corruption.</p>
<h2 id="future-opportunities">Future Opportunities</h2>
<p>Sharding across multiple archive files per bucket (directory) would be one enhancement. It would allow for round-robin writes with multiple appenders,
improving concurrency. Using multiple archive files per bucket also provides a mechanism to cap archive file sizes.</p>
<p>A mechanism for tombstoning files within an archive is also needed. As seen in the earlier hexdump, it might be possible to repurpose an existing header field to mark
content as deleted.  This would allow the offsets database to be reconstructed later, even after a crash or loss of metadata. Another idea is to write custom metadata
into the unused space within the 512-byte header block.  Whether this breaks compatibility with standard tar utilities remains an open question.</p>
<p>Compression and encryption are also worth exploring. Because the prototype seeks directly to file offsets and reads raw byte ranges, it’s feasible to compress file
content before appending it to the archive. Retrieval would involve decompressing on the fly after seeking to the file location within the archive. Similarly,
data-at-rest encryption could be supported by encrypting file contents during the write path and decrypting during reads. This allows per-object confidentiality
without relying on full-disk encryption or underlying filesystem support.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>It&rsquo;s oddly satisfying to bend old standards to new purposes, like using the tar format as the basis of an object store.  Putting this post together
has been a reminder on the types of challenges distributed file systems create when separating metadata from the data.  Simple things like marking
a file as deleted become complicated.</p>
<p>Let me know if this topic is interesting or you have follow-up suggestions.  I can be reached at <a href="https://bsky.app/profile/af9.us">Bluesky</a>.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
