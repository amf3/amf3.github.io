<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Homelab on Adam Faris</title>
    <link>http://localhost:1313/categories/homelab/</link>
    <description>Recent content in Homelab on Adam Faris</description>
    <generator>Hugo -- 0.147.8</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Aug 2023 07:38:23 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/homelab/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Elastic Block Store Design for Home Lab Use</title>
      <link>http://localhost:1313/articles/arch/aws_ebs/ebs/</link>
      <pubDate>Fri, 25 Aug 2023 07:38:23 -0700</pubDate>
      <guid>http://localhost:1313/articles/arch/aws_ebs/ebs/</guid>
      <description>&lt;h1 id=&#34;todo-rewrite--make-content-more-focused-on-the-message&#34;&gt;TODO: Rewrite &amp;amp; make content more focused on the message.&lt;/h1&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;I have a small home lab that I use for testing different software stacks. Lately I have been choosing a distributed
storage solution for use at home.  Usually I look at industry and scale down the solution.  This has lead to
conversations with colleagues and the question of &amp;ldquo;How did Amazon Web Services implement their Elastic Block Store
offering?&amp;rdquo;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="todo-rewrite--make-content-more-focused-on-the-message">TODO: Rewrite &amp; make content more focused on the message.</h1>
<h2 id="intro">Intro</h2>
<p>I have a small home lab that I use for testing different software stacks. Lately I have been choosing a distributed
storage solution for use at home.  Usually I look at industry and scale down the solution.  This has lead to
conversations with colleagues and the question of &ldquo;How did Amazon Web Services implement their Elastic Block Store
offering?&rdquo;.</p>
<h2 id="background">Background</h2>
<p>There are solutions that provide network storage like iSCSI, CIFS, or NFS.  These protocols can be grouped into two
data access methods.  One method will access data as a <em>file</em> &amp; the method is to access data as a <em>block device</em>.  Block
storage is a device that stores data in evenly spaced chunks called blocks.  An example block storage device is
the hard drive inside a computer.</p>
<p>CIFS &amp; NFS are protocols where data is accessed as a file.  iSCSI will access data at the block level. Sometimes
backup solutions like Apple&rsquo;s TimeMachine will obfuscate this by treating the file as a block device. From the
perspective of the storage server, it&rsquo;s providing NFS or CIFS access to the file so its file based access.</p>
<p>For me, iSCSI is the more interesting use case as it allows a physical host, VM, or container <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>, to access the block
device over the network. Having access to the underlying block device provides flexibility with data management.  An
example is being able to snapshot the block device as a backup or a point in time image for use in future
provisioning.</p>
<p>In my home lab I have tinkered with iSCSI and found that data access latency is bad without a dedicated storage-only
network connection.  Even with a dedicated connection, its arguable that a 1Gb/s network isn&rsquo;t
fast enough for a SAN.  Typically when SANs are mentioned companies pull out the checkbook because it involves custom
hardware. Elastic Block Storage is no exception to this statement.</p>
<h2 id="ebs-findings">EBS Findings</h2>
<p>Elastic Block Storage (EBS) is a storage offering from Amazon AWS.  EBS is a service that emulates a local block device
where data is persistently stored over the network.</p>
<p>AWS uses a combined approach to providing a performant storage solution to clients. <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>  This is done by using a
custom network stack that uses datagrams, specialized hardware that provides a bridge between storage &amp; networking,
and a minimized Linux kernel running the EC2 servers.</p>
<h3 id="network">Network</h3>
<p>AWS replaced TCP with a datagram based protocol named Scalable Reliable Datagram (SRD).  SRD supports equal cost
multipathing, congestion control, and reliable out of order delivery, leaving ordering to networking (OSI) layers above
SRD.</p>
<p>A summary of why SRD matters is it removes latency caused by the three-way TCP handshake &amp; congestion control delays
in TCP.</p>
<h3 id="data-processing-units">Data Processing Units</h3>
<p>Data Processing Units (DPU) are an interesting bit of hardware.  The DPU is a PCI card that has a onboard CPU, Memory, &amp;
SFP+ networking ports.  The DPU plugs into the server and gains access to the server&rsquo;s PCI lanes.  This allows it
emulate both a storage device, network interface cards (NIC), and provide out of band management.</p>
<p>I quickly realized the DPU, which AWS calls a Nitro card in marketing, is the magic sauce for EBS.  The Nitro card will
represent itself as a NVME storage device to the server&rsquo;s operating system (OS) and also handles networking to the EBS
volumes without the server&rsquo;s OS knowing it.  AWS even moved the SRD network stack into the Nitro card which means
networking is handled by the hardware, not software, making networking more efficient.</p>
<p>In addition to emulating the storage device, the Nitro card will also provide general networking for the server OS.  One
other function the Nitro card performs, is during server resets (reboots), the Nitro card will checksum the bios
to validate it hasn&rsquo;t been tampered with. Remember that its a computer on a PCI card with access to the PCI lanes of
the server its plugged into.</p>
<h3 id="kernel">Kernel</h3>
<p>AWS announced in 2019 that they were moving away from Xen to using KVM with Qemu for hosting their EC2 offering.  This
is relevant to the NVME storage interface provided by the Nitro card.</p>
<p>Qemu has the ability to directly access a NVME device by using a user-space driver.  Because the Nitro card provides
both storage and system network interfaces, there&rsquo;s no need for the linux kernel on the server to need a
storage or network driver.  This leads to a very lean kernel on the EC2 host, essentially turning it into a appliance.</p>
<h2 id="follow-up">Follow up</h2>
<p>Now we know that AWS is doing interesting things with both hardware &amp; software, how can it be applied to the home lab?
Well it can&rsquo;t because purchasing a pair of DPUs from Nvidia or Dell is beyond my budget. In addition to the $3000-$5000
cost per card, I also need to factor in the 200 watts of power used by each DPU.</p>
<p>I can get creative with networking by bonding multiple interfaces on the host into a single virtual interface.<br>
Bonding won&rsquo;t go beyond or above line speed, but it helps when there are multiple clients accessing
data on the same physical host.  Bonding is something I have experience with and I remember the entire connection can be
fragile when one of the links from the bonded pair fails.  This was back in 2010, so hopefully bonding works
better in 2023.</p>
<p>Similar to AWS, I am also using KVM with Qemu in my home lab.  For storage, Gluster FS has caught my eye.  With
distributed filesystems, managing the filesystem metadata can be complicated and Gluster FS has a simple metadata model.
Like NFS or CIFS, Gluster FS is another file based system. While my goal was to implement a local block store, because
Qemu has a Gluster driver built into it, the result is a file based storage system that appears as a block store to Qemu.</p>
<h2 id="references">References</h2>
<p>Bouffler B. In the search for performance, thereâ€™s more than one way to build a network. Amazon Web Services.
June 22, 2021.  Accessed August 20, 2023.
<a href="https://aws.amazon.com/blogs/hpc/in-the-search-for-performance-theres-more-than-one-way-to-build-a-network/">https://aws.amazon.com/blogs/hpc/in-the-search-for-performance-theres-more-than-one-way-to-build-a-network/</a></p>
<p>The Security Design of the AWS Nitro System. Amazon Web Services. November 18, 2022. Accessed August 20, 2023.
<a href="https://docs.aws.amazon.com/whitepapers/latest/security-design-of-aws-nitro-system/security-design-of-aws-nitro-system.html">https://docs.aws.amazon.com/whitepapers/latest/security-design-of-aws-nitro-system/security-design-of-aws-nitro-system.html</a></p>
<p>Baligh H. Serag E. Talaat S. Gaballah Y. DPUS: Acceleration Through Disaggregation. Dell Technologies. 2021.
Accessed August 20, 2023
<a href="https://education.dell.com/content/dam/dell-emc/documents/en-us/2021KS_Baligh-DPUs_Acceleration_Through_Disaggregation.pdf">https://education.dell.com/content/dam/dell-emc/documents/en-us/2021KS_Baligh-DPUs_Acceleration_Through_Disaggregation.pdf</a></p>
<p>Disk Images. Qemu Project August 2023. Accessed August 20, 2023.
<a href="https://qemu-project.gitlab.io/qemu/system/images.html#nvme-disk-images">https://qemu-project.gitlab.io/qemu/system/images.html#nvme-disk-images</a></p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Kubernetes can access block storage with Container Storage Interface (CSI) plugins. Docker volumes also have
plugins that support block storage.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>I am not affiliated with AWS nor do I have internal contacts with AWS.  The content on this page is my
interpretation from reading publicly available marketing documentation.  I feel I&rsquo;m close enough in my interpretation
for a layman&rsquo;s understanding of how EBS is implemented.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
  </channel>
</rss>
