[{"content":"Intro I have a small home lab that I use for testing different software stacks. Lately I have been choosing a distributed storage solution for use at home. Usually I look at industry and scale down the solution. This has lead to conversations with colleagues and the question of \u0026ldquo;How did Amazon Web Services implement their Elastic Block Store offering?\u0026rdquo;.\nBackground There are solutions that provide network storage like iSCSI, CIFS, or NFS. These protocols can be grouped into two data access methods. One method will access data as a file \u0026amp; the method is to access data as a block device. Block storage is a device that stores data in evenly spaced chunks called blocks. An example block storage device is the hard drive inside a computer.\nCIFS \u0026amp; NFS are protocols where data is accessed as a file. iSCSI will access data at the block level. Sometimes backup solutions like Apple\u0026rsquo;s TimeMachine will obfuscate this by treating the file as a block device. From the perspective of the storage server, it\u0026rsquo;s providing NFS or CIFS access to the file so its file based access.\nFor me, iSCSI is the more interesting use case as it allows a physical host, VM, or container 1, to access the block device over the network. Having access to the underlying block device provides flexibility with data management. An example is being able to snapshot the block device as a backup or a point in time image for use in future provisioning.\nIn my home lab I have tinkered with iSCSI and found that data access latency is bad without a dedicated storage-only network connection. Even with a dedicated connection, its arguable that a 1Gb/s network isn\u0026rsquo;t fast enough for a SAN. Typically when SANs are mentioned companies pull out the checkbook because it involves custom hardware. Elastic Block Storage is no exception to this statement.\nEBS Findings Elastic Block Storage (EBS) is a storage offering from Amazon AWS. EBS is a service that emulates a local block device where data is persistently stored over the network.\nAWS uses a combined approach to providing a performant storage solution to clients. 2 This is done by using a custom network stack that uses datagrams, specialized hardware that provides a bridge between storage \u0026amp; networking, and a minimized Linux kernel running the EC2 servers.\nNetwork AWS replaced TCP with a datagram based protocol named Scalable Reliable Datagram (SRD). SRD supports equal cost multipathing, congestion control, and reliable out of order delivery, leaving ordering to networking (OSI) layers above SRD.\nA summary of why SRD matters is it removes latency caused by the three-way TCP handshake \u0026amp; congestion control delays in TCP.\nData Processing Units Data Processing Units (DPU) are an interesting bit of hardware. The DPU is a PCI card that has a onboard CPU, Memory, \u0026amp; SFP+ networking ports. The DPU plugs into the server and gains access to the server\u0026rsquo;s PCI lanes. This allows it emulate both a storage device, network interface cards (NIC), and provide out of band management.\nI quickly realized the DPU, which AWS calls a Nitro card in marketing, is the magic sauce for EBS. The Nitro card will represent itself as a NVME storage device to the server\u0026rsquo;s operating system (OS) and also handles networking to the EBS volumes without the server\u0026rsquo;s OS knowing it. AWS even moved the SRD network stack into the Nitro card which means networking is handled by the hardware, not software, making networking more efficient.\nIn addition to emulating the storage device, the Nitro card will also provide general networking for the server OS. One other function the Nitro card performs, is during server resets (reboots), the Nitro card will checksum the bios to validate it hasn\u0026rsquo;t been tampered with. Remember that its a computer on a PCI card with access to the PCI lanes of the server its plugged into.\nKernel AWS announced in 2019 that they were moving away from Xen to using KVM with Qemu for hosting their EC2 offering. This is relevant to the NVME storage interface provided by the Nitro card.\nQemu has the ability to directly access a NVME device by using a user-space driver. Because the Nitro card provides both storage and system network interfaces, there\u0026rsquo;s no need for the linux kernel on the server to need a storage or network driver. This leads to a very lean kernel on the EC2 host, essentially turning it into a appliance.\nFollow up Now we know that AWS is doing interesting things with both hardware \u0026amp; software, how can it be applied to the home lab? Well it can\u0026rsquo;t because purchasing a pair of DPUs from Nvidia or Dell is beyond my budget. In addition to the $3000-$5000 cost per card, I also need to factor in the 200 watts of power used by each DPU.\nI can get creative with networking by bonding multiple interfaces on the host into a single virtual interface.\nBonding won\u0026rsquo;t go beyond or above line speed, but it helps when there are multiple clients accessing data on the same physical host. Bonding is something I have experience with and I remember the entire connection can be fragile when one of the links from the bonded pair fails. This was back in 2010, so hopefully bonding works better in 2023.\nSimilar to AWS, I am also using KVM with Qemu in my home lab. For storage, Gluster FS has caught my eye. With distributed filesystems, managing the filesystem metadata can be complicated and Gluster FS has a simple metadata model. Like NFS or CIFS, Gluster FS is another file based system. While my goal was to implement a local block store, because Qemu has a Gluster driver built into it, the result is a file based storage system that appears as a block store to Qemu.\nReferences Bouffler B. In the search for performance, thereâ€™s more than one way to build a network. Amazon Web Services. June 22, 2021. Accessed August 20, 2023. https://aws.amazon.com/blogs/hpc/in-the-search-for-performance-theres-more-than-one-way-to-build-a-network/\nThe Security Design of the AWS Nitro System. Amazon Web Services. November 18, 2022. Accessed August 20, 2023. https://docs.aws.amazon.com/whitepapers/latest/security-design-of-aws-nitro-system/security-design-of-aws-nitro-system.html\nBaligh H. Serag E. Talaat S. Gaballah Y. DPUS: Acceleration Through Disaggregation. Dell Technologies. 2021. Accessed August 20, 2023 https://education.dell.com/content/dam/dell-emc/documents/en-us/2021KS_Baligh-DPUs_Acceleration_Through_Disaggregation.pdf\nDisk Images. Qemu Project August 2023. Accessed August 20, 2023. https://qemu-project.gitlab.io/qemu/system/images.html#nvme-disk-images\nKubernetes can access block storage with Container Storage Interface (CSI) plugins. Docker volumes also have plugins that support block storage.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI am not affiliated with AWS nor do I have internal contacts with AWS. The content on this page is my interpretation from reading publicly available marketing documentation. I feel I\u0026rsquo;m close enough in my interpretation for a layman\u0026rsquo;s understanding of how EBS is implemented.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://amf3.github.io/articles/arch/aws_ebs/ebs/","summary":"Intro I have a small home lab that I use for testing different software stacks. Lately I have been choosing a distributed storage solution for use at home. Usually I look at industry and scale down the solution. This has lead to conversations with colleagues and the question of \u0026ldquo;How did Amazon Web Services implement their Elastic Block Store offering?\u0026rdquo;.\nBackground There are solutions that provide network storage like iSCSI, CIFS, or NFS.","title":"Elastic Block Store Design for Home Lab Use"},{"content":"Intro I\u0026rsquo;ll occasionally browse [Hacker News[(https://news.ycombinator.com) or Lobsters for industry news. I typically find more value from subscribing to newsletters.\nNewsletters The newsletter owners have done a great job of not spaming the list. Usually they arrive in the inbox on Sunday morning so it\u0026rsquo;s good timing to read them while relaxing with a cup of coffee. While there is some overlap in topics, the articles themselves don\u0026rsquo;t overlap.\nDevops weekly Devops Weekly is a great collection of recent articles that cover topics like deployments, provisioning, observability, or even incident management.\nMonitoring weekly Monitoring Weekly is another great list. As implied by its name, it\u0026rsquo;s focus is on monitoring \u0026amp; observability.\nBlogs Julia Evans A great blog to follow as it covers both technical \u0026amp; career disucssions. Charity Majors Another blog that covers technical \u0026amp; career discussions Books The following is a list of of books that I\u0026rsquo;ve found helpful.\nWorking Effectively with Legacy Code, Michael C Feathers The Clean Coder: A Code of Conduct for Professional Programmers, Robert C Martin Linux Kernel Development: Robert Love ","permalink":"http://amf3.github.io/about/reading_list/","summary":"Intro I\u0026rsquo;ll occasionally browse [Hacker News[(https://news.ycombinator.com) or Lobsters for industry news. I typically find more value from subscribing to newsletters.\nNewsletters The newsletter owners have done a great job of not spaming the list. Usually they arrive in the inbox on Sunday morning so it\u0026rsquo;s good timing to read them while relaxing with a cup of coffee. While there is some overlap in topics, the articles themselves don\u0026rsquo;t overlap.\nDevops weekly Devops Weekly is a great collection of recent articles that cover topics like deployments, provisioning, observability, or even incident management.","title":"Reading Lists"},{"content":"How to get in touch GitHub: https://github.com/amf3 LinkedIn: https://www.linkedin.com/in/adammfaris/ BlueSky Social: https://@amf3.bsky.social ","permalink":"http://amf3.github.io/about/contact/","summary":"How to get in touch GitHub: https://github.com/amf3 LinkedIn: https://www.linkedin.com/in/adammfaris/ BlueSky Social: https://@amf3.bsky.social ","title":"Contact"}]