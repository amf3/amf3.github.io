<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Using Tar Files as Object Store Storage | Adam Faris</title>
<meta name="keywords" content="">
<meta name="description" content="Implementing Object Store storage with Log Structured Archives.">
<meta name="author" content="">
<link rel="canonical" href="https://amf3.github.io/articles/storage/tar_objectstore/">
<meta name="google-site-verification" content="6ZFu-1_Lir3DsFJP8sshXEJ1_SjtFUw9TIISOcaJh7E">
<meta name="msvalidate.01" content="C1E02AC59FE7ECBDB6D9EFB7D5E02B65">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://amf3.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://amf3.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://amf3.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://amf3.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://amf3.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://amf3.github.io/articles/storage/tar_objectstore/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-MKR06D6KGD"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-MKR06D6KGD');
        }
      </script><meta property="og:url" content="https://amf3.github.io/articles/storage/tar_objectstore/">
  <meta property="og:site_name" content="Adam Faris">
  <meta property="og:title" content="Using Tar Files as Object Store Storage">
  <meta property="og:description" content="Implementing Object Store storage with Log Structured Archives.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="articles">
    <meta property="article:published_time" content="2025-05-30T16:46:07-07:00">
    <meta property="article:modified_time" content="2025-05-30T16:46:07-07:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Using Tar Files as Object Store Storage">
<meta name="twitter:description" content="Implementing Object Store storage with Log Structured Archives.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "articles",
      "item": "https://amf3.github.io/articles/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Using Tar Files as Object Store Storage",
      "item": "https://amf3.github.io/articles/storage/tar_objectstore/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using Tar Files as Object Store Storage",
  "name": "Using Tar Files as Object Store Storage",
  "description": "Implementing Object Store storage with Log Structured Archives.",
  "keywords": [
    
  ],
  "articleBody": "I’m looking at how object storage systems manage data on disk. Especially the idea of using append only archives with an index for fast retrieveal. While reading Facebook’s Haystack design, I noticed similarities to the tar file format and the potential to implement something similar at the local scale.\nHaystack Overview There are several components mentioned in the original Haystack paper, but at the core is the Haystack Store, where end user image files are physically kept. Instead of writing files directly to the filesystem, images are appended to a large file called a volume, which acts as an append-only archive. Each volume is typically capped at around 100 GB and is aligned to 8-byte offsets. Image files within this volume are referred to as needles.\nA volume begins with a superblock (the paper doesn’t describe this in detail), followed by the header for the first needle (file). Each needle within the volume has its own header, containing metadata like file size, checksums, and flags. The flags field includes a bit to indicate deletion status.\nSince the volume is append-only, deletions don’t reclaim space—they’re simply marked as deleted in the needle’s header. A background process can later compact the volume if needed. To keep track of where each needle is within the file, an in-memory index maps file IDs to byte offsets.\nWhen a read request comes in, the Haystack Store performs a direct seek to the needle’s offset, verifies the flags to check if it’s deleted, and returns the data if is not tombstoned. Deletions update both the in-memory index and the needle’s header to mark the entry as removed.\nThis model provides two big wins:\nStorage efficiency: Small files, like 1 KB thumbnails, don’t waste space the way they would on a traditional filesystem with 4 KB blocks. Instead of allocating a full block per file, they’re packed into a shared archive. Fast retrieval: There’s no need to scan directory structures or fetch inode metadata. With an open file handle to the volume and an in-memory index, reads are just a seek and a read. Tar Storage The tape archive format (tar) is surprisingly similar to the Haystack volume. While tar files don’t implement a superblock, each file entry is stored at a 512-byte aligned offset, and each file includes its own metadata header. This format allows us to calculate the offset of each file within the archive.\nHere’s a hexdump of a simple test.tar archive containing two files: a.txt and b.txt.\nIn this example:\na.txt contains the string “foo\\n”, and b.txt contains “bar\\n”. Each file is preceded by a 512-byte header containing metadata like filename, permissions, and ownership. Since a.txt is only 4 bytes long, it’s followed by null padding to align the next file (b.txt) to the 512-byte boundary. The offset for b.txt starts at 0x400 (1024 bytes), which is a clean 512-byte multiple. Although tar uses more padding than Haystack (which aligns to 8-byte offsets), its fixed alignment still enables efficient offset tracking and data retrieval. Once the byte offsets of each file are known, accessing a file is just a matter of seeking to the right position and reading the data.\nTar also provides nice recovery properties:\nAn index of offsets can always be created by reading the tar file and recording the header positions as offsets. Because this is a standard tar file, common tools like tar and cpio can extract the objects directly without the need for custom tooling. Python Prototype Tar archives are typically read sequentially from start to finish. But if we build an index of byte offsets, we can enable random access to individual files. Let’s explore this with a prototype in Python using the test.tar archive shown in the earlier hexdump. A copy of the archive can be downloaded from here.\nWe have two options for building this prototype:\nThe hard way, by manually parsing byte offsets directly from the tar header. The batteries-included way, using Python’s built-in tarfile module to extract header information cleanly. If you’re curious, fields and byte-offsets within file headers are listed in GNU’s tar header definition.\nHere’s an example of the batteries-included approach using the tarfile module. I’ll scan the archive, read each file’s size and data offset, and store that in a dictionary:\n#!/usr/bin/env python3 import math import tarfile from collections import defaultdict from typing import Dict ARCHIVE_FILE = \"test.tar\" BYTE_ALIGNMENT = 512 def read_header(archive: str) -\u003e Dict: entities = defaultdict(list) header_offset = 0 with open(archive, 'rb') as f: while True: f.seek(header_offset) header = f.read(BYTE_ALIGNMENT) if header == b'\\0' * BYTE_ALIGNMENT: break # End of archive, trailer will contain two 512-byte blocks of zeros try: tarinfo = tarfile.TarInfo.frombuf(header, encoding=\"utf-8\", errors=\"surrogateescape\") file_name = tarinfo.name file_size = tarinfo.size data_offset = header_offset + BYTE_ALIGNMENT entities[file_name].append([file_size, data_offset]) except Exception as e: print(f\"Error parsing header at offset {header_offset}: {e}\") break padding = math.ceil(file_size / BYTE_ALIGNMENT) * BYTE_ALIGNMENT header_offset += BYTE_ALIGNMENT + padding return entities tar_data = read_header(ARCHIVE_FILE) for file_name, attributes in tar_data.items(): for attribute in attributes: print(f\"filename: {file_name:\u003c10} attributes: file_size: {attribute[0]:\u003c6} data_offset: {attribute[1]:\u003c6}\") Example output.\n% python offsets.py filename: a.txt attributes: file_size: 4 data_offset: 512 filename: a.txt attributes: file_size: 13 data_offset: 2560 filename: b.txt attributes: file_size: 4 data_offset: 1536 Notice that a.txt appears twice, each with a different file size and offset. This is expected. It’s possible to append files to a tar archive using tar -rf. When a file is re-added, it becomes the newer version.\nIn our example archive file, a.txt was modified and appended, producing two versions in the archive. Traditional tar extraction reads from the beginning and overwrites earlier entries as it encounters newer ones. But by having an index of offsets, I can seek directly to either version and extract it manually.\nHere’s a helper function to extract a specific version of a file:\ndef extract_file(archive: str, file_name: str, offset: int, read_bytes: int): try: with open(archive, 'rb') as f: f.seek(offset) data = f.read(read_bytes) with open(f\"{file_name}@{offset:08x}\", 'wb') as out: out.write(data) except Exception as e: print(f\"Error extracting {file_name} at offset: {offset:08x}\") Add the following lines in main to extract both versions of a.txt:\nextract_file(ARCHIVE_FILE, \"a.txt\", 512, 4) extract_file(ARCHIVE_FILE, \"a.txt\", 2560, 13) And the result:\n% ls -latr a.txt@* -rw-r--r--@ 1 adam staff 4 Jun 6 22:07 a.txt@00000200 -rw-r--r--@ 1 adam staff 13 Jun 6 22:07 a.txt@00000a00 % cat a.txt@00000200 foo % cat a.txt@00000a00 foo fooooooo This demonstrates simple object versioning using nothing more than tar’s existing append behavior and a bit of byte-level introspection.\nTrade-Offs and Limitations As with Haystack, there’s not an efficient way to delete content from a tar archive without rewriting the entire file. Instead, deletion requires marking entries as removed in the offsets database. Unlike Haystack which has explicit flags in its header, tar headers offer no such field. Meaning if we lose the index, we can no longer distinguish active content from deleted entries by scanning the archive.\nThe data removal limitation also contributes to archive fragmentation. Until a process rewrites the archive to remove tombstoned data, deleted files remain in place, consuming storage.\nAnother trade-off lies in tar’s alignment strategy, both headers and data are aligned to 512-byte blocks. In typical usage, tar archives are compressed, which minimizes the overhead of null padding. But for this design to support random access, the archive must remain uncompressed. Filesystems like ZFS and Btrfs can apply transparent compression at the block level, but relying on underlying filesystem isn’t ideal for portability. Haystack uses 8-byte alignment, which results in less padding and more efficient use of space.\nAlso worth noting, my prototype doesn’t implement any kind of write locking. If this were used in a concurrent setting like a web application storing assets, appends would require locking the archive to prevent corruption.\nFuture Opportunities Sharding across multiple archive files per bucket (directory) would be one enhancement. It would allow for round-robin writes with multiple appenders, improving concurrency. Using multiple archive files per bucket also provides a mechanism to cap archive file sizes.\nA mechanism for tombstoning files within an archive is also needed. As seen in the earlier hexdump, it might be possible to repurpose an existing header field to mark content as deleted. This would allow the offsets database to be reconstructed later, even after a crash or loss of metadata. Another idea is to write custom metadata into the unused space within the 512-byte header block. Whether this breaks compatibility with standard tar utilities remains an open question.\nCompression and encryption are also worth exploring. Because the prototype seeks directly to file offsets and reads raw byte ranges, it’s feasible to compress file content before appending it to the archive. Retrieval would involve decompressing on the fly after seeking to the file location within the archive. Similarly, data-at-rest encryption could be supported by encrypting file contents during the write path and decrypting during reads. This allows per-object confidentiality without relying on full-disk encryption or underlying filesystem support.\nFinal Thoughts It’s oddly satisfying to bend old standards to new purposes, like using the tar format as the basis of an object store. Putting this post together has been a reminder on the types of challenges distributed file systems create when separating metadata from the data. Simple things like marking a file as deleted become complicated.\nLet me know if this topic is interesting or you have follow-up suggestions. I can be reached at Bluesky.\n",
  "wordCount" : "1553",
  "inLanguage": "en",
  "datePublished": "2025-05-30T16:46:07-07:00",
  "dateModified": "2025-05-30T16:46:07-07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://amf3.github.io/articles/storage/tar_objectstore/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Adam Faris",
    "logo": {
      "@type": "ImageObject",
      "url": "https://amf3.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://amf3.github.io/" accesskey="h" title="Adam Faris (Alt + H)">Adam Faris</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://amf3.github.io/search/" title="search (Alt &#43; /)" accesskey=/>
                    <span>search</span>
                </a>
            </li>
            <li>
                <a href="https://amf3.github.io/articles/" title="articles">
                    <span>articles</span>
                </a>
            </li>
            <li>
                <a href="https://amf3.github.io/about/" title="about">
                    <span>about</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://amf3.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://amf3.github.io/articles/">articles</a></div>
    <h1 class="post-title entry-hint-parent">
      Using Tar Files as Object Store Storage
    </h1>
    <div class="post-description">
      Implementing Object Store storage with Log Structured Archives.
    </div>
    <div class="post-meta"><span title='2025-05-30 16:46:07 -0700 PDT'>May 30, 2025</span>&nbsp;·&nbsp;1553 words

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#haystack-overview" aria-label="Haystack Overview">Haystack Overview</a></li>
                <li>
                    <a href="#tar-storage" aria-label="Tar Storage">Tar Storage</a></li>
                <li>
                    <a href="#python-prototype" aria-label="Python Prototype">Python Prototype</a></li>
                <li>
                    <a href="#trade-offs-and-limitations" aria-label="Trade-Offs and Limitations">Trade-Offs and Limitations</a></li>
                <li>
                    <a href="#future-opportunities" aria-label="Future Opportunities">Future Opportunities</a></li>
                <li>
                    <a href="#final-thoughts" aria-label="Final Thoughts">Final Thoughts</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>I&rsquo;m looking at how object storage systems manage data on disk. Especially the idea of using append only archives with an index for fast retrieveal.  While reading
Facebook&rsquo;s Haystack design, I noticed similarities to the tar file format and the potential to implement something similar at the local scale.</p>
<h2 id="haystack-overview">Haystack Overview<a hidden class="anchor" aria-hidden="true" href="#haystack-overview">#</a></h2>
<p>There are several components mentioned in the original <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf">Haystack paper</a>, but at
the core is the Haystack Store, where end user image files are physically kept. Instead of writing files directly to the filesystem, images are appended
to a large file called a <strong>volume</strong>, which acts as an append-only archive. Each volume is typically capped at around 100 GB and is aligned to 8-byte
offsets.  Image files within this volume are referred to as <strong>needles</strong>.</p>
<p><img alt="Haystack Volume Description" loading="lazy" src="/articles/storage/tar_objectstore/assets/needles.png#center"></p>
<p>A volume begins with a superblock (the paper doesn’t describe this in detail), followed by the header for the first needle (file). Each needle within
the volume has its own header, containing metadata like file size, checksums, and flags. The flags field includes a bit to indicate deletion status.</p>
<p>Since the volume is append-only, deletions don’t reclaim space—they&rsquo;re simply marked as deleted in the needle’s header. A background process can later
compact the volume if needed. To keep track of where each needle is within the file, an in-memory index maps file IDs to byte offsets.</p>
<p>When a read request comes in, the Haystack Store performs a direct seek to the needle’s offset, verifies the flags to check if it&rsquo;s deleted, and returns
the data if is not tombstoned.  Deletions update both the in-memory index and the needle’s header to mark the entry as removed.</p>
<p>This model provides two big wins:</p>
<ul>
<li><strong>Storage efficiency:</strong> Small files, like 1 KB thumbnails, don’t waste space the way they would on a traditional filesystem with 4 KB blocks. Instead of allocating a full block per file, they&rsquo;re packed into a shared archive.</li>
<li><strong>Fast retrieval:</strong> There’s no need to scan directory structures or fetch inode metadata. With an open file handle to the volume and an in-memory index, reads are just a seek and a read.</li>
</ul>
<h2 id="tar-storage">Tar Storage<a hidden class="anchor" aria-hidden="true" href="#tar-storage">#</a></h2>
<p>The tape archive format (<strong>tar</strong>) is surprisingly similar to the Haystack volume. While tar files don’t implement a superblock, each file entry is stored at a 512-byte
aligned offset, and each file includes its own metadata header. This format allows us to calculate the offset of each file within the archive.</p>
<p>Here’s a hexdump of a simple test.tar archive containing two files: a.txt and b.txt.</p>
<p><img alt="Hexdump Tarfile" loading="lazy" src="/articles/storage/tar_objectstore/assets/hexdump.png#center"></p>
<p>In this example:</p>
<ul>
<li>a.txt contains the string &ldquo;foo\n&rdquo;, and b.txt contains &ldquo;bar\n&rdquo;.</li>
<li>Each file is preceded by a 512-byte header containing metadata like filename, permissions, and ownership.</li>
<li>Since a.txt is only 4 bytes long, it’s followed by null padding to align the next file (b.txt) to the 512-byte boundary.</li>
<li>The offset for b.txt starts at 0x400 (1024 bytes), which is a clean 512-byte multiple.</li>
</ul>
<p>Although tar uses more padding than Haystack (which aligns to 8-byte offsets), its fixed alignment still enables efficient offset tracking and data retrieval. Once the
byte offsets of each file are known, accessing a file is just a matter of seeking to the right position and reading the data.</p>
<p>Tar also provides nice recovery properties:</p>
<ul>
<li>An index of offsets can always be created by reading the tar file and recording the header positions as offsets.</li>
<li>Because this is a standard tar file, common tools like tar and cpio can extract the objects directly without the need for custom tooling.</li>
</ul>
<h2 id="python-prototype">Python Prototype<a hidden class="anchor" aria-hidden="true" href="#python-prototype">#</a></h2>
<p>Tar archives are typically read sequentially from start to finish. But if we build an index of byte offsets, we can enable random access to individual files.
Let’s explore this with a prototype in Python using the test.tar archive shown in the earlier hexdump. A copy of the archive can be downloaded
from <a href="./assets/test.tar">here</a>.</p>
<p>We have two options for building this prototype:</p>
<ul>
<li>The hard way, by manually parsing byte offsets directly from the tar header.</li>
</ul>
<p><img alt="Screenshot of byte offsets" loading="lazy" src="/articles/storage/tar_objectstore/assets/the_hard_way.png"></p>
<ul>
<li>The batteries-included way, using Python’s built-in <strong>tarfile</strong> module to extract header information cleanly.</li>
</ul>
<p>If you’re curious, fields and byte-offsets within file headers are listed
in <a href="(https://cgit.git.savannah.gnu.org/cgit/tar.git/tree/src/tar.h#n24)">GNU&rsquo;s tar header definition</a>.</p>
<p><img alt="Screenshot of the struct" loading="lazy" src="/articles/storage/tar_objectstore/assets/header_struct.png"></p>
<p>Here’s an example of the batteries-included approach using the <strong>tarfile</strong> module. I’ll scan the archive, read each file’s size and data offset, and store that in a dictionary:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e">#!/usr/bin/env python3</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tarfile
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> collections <span style="color:#f92672">import</span> defaultdict
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> typing <span style="color:#f92672">import</span> Dict
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ARCHIVE_FILE <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;test.tar&#34;</span>
</span></span><span style="display:flex;"><span>BYTE_ALIGNMENT <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">read_header</span>(archive: str) <span style="color:#f92672">-&gt;</span> Dict:
</span></span><span style="display:flex;"><span>    entities <span style="color:#f92672">=</span> defaultdict(list)
</span></span><span style="display:flex;"><span>    header_offset <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">while</span> <span style="color:#66d9ef">True</span>:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(header_offset)
</span></span><span style="display:flex;"><span>            header <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(BYTE_ALIGNMENT)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> header <span style="color:#f92672">==</span> <span style="color:#e6db74">b</span><span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\0</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">*</span> BYTE_ALIGNMENT:
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>  <span style="color:#75715e"># End of archive, trailer will contain two 512-byte blocks of zeros</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>                tarinfo <span style="color:#f92672">=</span> tarfile<span style="color:#f92672">.</span>TarInfo<span style="color:#f92672">.</span>frombuf(header, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>, errors<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;surrogateescape&#34;</span>)
</span></span><span style="display:flex;"><span>                file_name <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>name
</span></span><span style="display:flex;"><span>                file_size <span style="color:#f92672">=</span> tarinfo<span style="color:#f92672">.</span>size
</span></span><span style="display:flex;"><span>                data_offset <span style="color:#f92672">=</span> header_offset <span style="color:#f92672">+</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>                entities[file_name]<span style="color:#f92672">.</span>append([file_size, data_offset])
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error parsing header at offset </span><span style="color:#e6db74">{</span>header_offset<span style="color:#e6db74">}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{</span>e<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            padding <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>ceil(file_size <span style="color:#f92672">/</span> BYTE_ALIGNMENT) <span style="color:#f92672">*</span> BYTE_ALIGNMENT
</span></span><span style="display:flex;"><span>            header_offset <span style="color:#f92672">+=</span> BYTE_ALIGNMENT <span style="color:#f92672">+</span> padding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> entities
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tar_data <span style="color:#f92672">=</span> read_header(ARCHIVE_FILE)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> file_name, attributes <span style="color:#f92672">in</span> tar_data<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> attribute <span style="color:#f92672">in</span> attributes:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;filename: </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;10</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> attributes: file_size: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> data_offset: </span><span style="color:#e6db74">{</span>attribute[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">&lt;6</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Example output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% python offsets.py
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">512</span>   
</span></span><span style="display:flex;"><span>filename: a.txt      attributes: file_size: <span style="color:#ae81ff">13</span>     data_offset: <span style="color:#ae81ff">2560</span>  
</span></span><span style="display:flex;"><span>filename: b.txt      attributes: file_size: <span style="color:#ae81ff">4</span>      data_offset: <span style="color:#ae81ff">1536</span>  
</span></span></code></pre></div><p>Notice that a.txt appears twice, each with a different file size and offset. This is expected. It’s possible to append files to a tar archive using <strong>tar -rf</strong>.
When a file is re-added, it becomes the newer version.</p>
<p>In our example archive file, <strong>a.txt</strong> was modified and appended, producing two versions in the archive. Traditional tar extraction reads from the beginning and
overwrites earlier entries as it encounters newer ones. But by having an index of offsets, I can seek directly to either version and extract it manually.</p>
<p>Here’s a helper function to extract a specific version of a file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">extract_file</span>(archive: str, file_name: str, offset: int, read_bytes: int):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">try</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> open(archive, <span style="color:#e6db74">&#39;rb&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>            f<span style="color:#f92672">.</span>seek(offset)
</span></span><span style="display:flex;"><span>            data <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read(read_bytes)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74">@</span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>, <span style="color:#e6db74">&#39;wb&#39;</span>) <span style="color:#66d9ef">as</span> out:
</span></span><span style="display:flex;"><span>                out<span style="color:#f92672">.</span>write(data)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">except</span> <span style="color:#a6e22e">Exception</span> <span style="color:#66d9ef">as</span> e:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Error extracting </span><span style="color:#e6db74">{</span>file_name<span style="color:#e6db74">}</span><span style="color:#e6db74"> at offset: </span><span style="color:#e6db74">{</span>offset<span style="color:#e6db74">:</span><span style="color:#e6db74">08x</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span></code></pre></div><p>Add the following lines in main to extract both versions of <strong>a.txt</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>extract_file(ARCHIVE_FILE, <span style="color:#e6db74">&#34;a.txt&#34;</span>, <span style="color:#ae81ff">2560</span>, <span style="color:#ae81ff">13</span>)
</span></span></code></pre></div><p>And the result:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>% ls -latr a.txt@*
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff   <span style="color:#ae81ff">4</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000200
</span></span><span style="display:flex;"><span>-rw-r--r--@ <span style="color:#ae81ff">1</span> adam  staff  <span style="color:#ae81ff">13</span> Jun  <span style="color:#ae81ff">6</span> 22:07 a.txt@00000a00
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000200
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>% cat a.txt@00000a00
</span></span><span style="display:flex;"><span>foo
</span></span><span style="display:flex;"><span>fooooooo
</span></span></code></pre></div><p>This demonstrates simple object versioning using nothing more than tar’s existing append behavior and a bit of byte-level introspection.</p>
<h2 id="trade-offs-and-limitations">Trade-Offs and Limitations<a hidden class="anchor" aria-hidden="true" href="#trade-offs-and-limitations">#</a></h2>
<p>As with Haystack, there&rsquo;s not an efficient way to delete content from a tar archive without rewriting the entire file. Instead, deletion requires marking entries
as removed in the offsets database. Unlike Haystack which has explicit flags in its header, tar headers offer no such field. Meaning if we lose the index, we
can no longer distinguish active content from deleted entries by scanning the archive.</p>
<p>The data removal limitation also contributes to archive fragmentation. Until a process rewrites the archive to remove tombstoned data, deleted files remain in place,
consuming storage.</p>
<p>Another trade-off lies in tar&rsquo;s alignment strategy, both headers and data are aligned to 512-byte blocks. In typical usage, tar archives are compressed, which
minimizes the overhead of null padding. But for this design to support random access, the archive must remain uncompressed. Filesystems like ZFS and Btrfs can
apply transparent compression at the block level, but relying on underlying filesystem isn&rsquo;t ideal for portability. Haystack uses 8-byte alignment, which results
in less padding and more efficient use of space.</p>
<p>Also worth noting, my prototype doesn’t implement any kind of write locking. If this were used in a concurrent setting like a web application storing
assets, appends would require locking the archive to prevent corruption.</p>
<h2 id="future-opportunities">Future Opportunities<a hidden class="anchor" aria-hidden="true" href="#future-opportunities">#</a></h2>
<p>Sharding across multiple archive files per bucket (directory) would be one enhancement. It would allow for round-robin writes with multiple appenders,
improving concurrency. Using multiple archive files per bucket also provides a mechanism to cap archive file sizes.</p>
<p>A mechanism for tombstoning files within an archive is also needed. As seen in the earlier hexdump, it might be possible to repurpose an existing header field to mark
content as deleted.  This would allow the offsets database to be reconstructed later, even after a crash or loss of metadata. Another idea is to write custom metadata
into the unused space within the 512-byte header block.  Whether this breaks compatibility with standard tar utilities remains an open question.</p>
<p>Compression and encryption are also worth exploring. Because the prototype seeks directly to file offsets and reads raw byte ranges, it’s feasible to compress file
content before appending it to the archive. Retrieval would involve decompressing on the fly after seeking to the file location within the archive. Similarly,
data-at-rest encryption could be supported by encrypting file contents during the write path and decrypting during reads. This allows per-object confidentiality
without relying on full-disk encryption or underlying filesystem support.</p>
<h2 id="final-thoughts">Final Thoughts<a hidden class="anchor" aria-hidden="true" href="#final-thoughts">#</a></h2>
<p>It&rsquo;s oddly satisfying to bend old standards to new purposes, like using the tar format as the basis of an object store.  Putting this post together
has been a reminder on the types of challenges distributed file systems create when separating metadata from the data.  Simple things like marking
a file as deleted become complicated.</p>
<p>Let me know if this topic is interesting or you have follow-up suggestions.  I can be reached at <a href="https://bsky.app/profile/af9.us">Bluesky</a>.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://amf3.github.io/">Adam Faris</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
